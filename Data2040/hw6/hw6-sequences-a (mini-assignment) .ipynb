{"metadata":{},"nbformat":4,"nbformat_minor":0,"cells":[{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 1"]},{"cell_type":"markdown","metadata":{"prismiaId":"b53abb39-6b5f-4ebd-93e2-40f9e2182fec","trusted":true,"editable":false,"deletable":false},"source":["![](https://firebasestorage.googleapis.com/v0/b/prismia.appspot.com/o/user-images%252Fimage-84dabff3-51aa-477c-9201-756f22ed4d88.png?alt=media&token=abc957e0-5eb5-4883-b9ba-8cee42143d1a)\n\nUsing this [colab-notebook stencil](https://drive.google.com/file/d/1NcWzchZFKh_yQLRQ-tzcakp5ocPOXVNs/view?usp=sharing), you will create a simple character-based tweet generation model.\n\nInstructions:  There is a Prismia problem corresponding to each **Task** in the notebook, for each one \n1. Provide a copy and paste your completed code cell(s).  \n2. Then provide a written summary of how the code cell(s) operates.\n3. Include relevant notes (and where appropriate example output) of its operation with respect to the supplied dataset. (You may use multiple code cells to describe this last step)\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"c319c92e-d5b6-4909-bf62-2a8e1e1bf1c2","trusted":true,"editable":false,"deletable":false},"source":["® Here is a course staff accessible link to my completed notebook:\n"]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 2"]},{"cell_type":"markdown","metadata":{"prismiaId":"131d594d-8b4c-4c41-80b2-52833dbc39f0","trusted":true,"editable":false,"deletable":false},"source":["### ®[5] Task ETL\nUsing the code cell below write some ETL code to load the data using the link above, and store it in memory as a single (very long) string. The data is small enough to do this. ****Note:**** When working with a larger [text corpus](https://en.wikipedia.org/wiki/Text_corpus), the ETL would need to store the intermediates to disk). \n\nJoin individual tweets with a new line character (\"\\n\") or some other special character.  In many applications, some additional filtering and transformations character (or word) might be applied at this step, but there is no need to do so in this assignment.\n"]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 3"]},{"cell_type":"markdown","metadata":{"prismiaId":"80242264-bce9-44d6-b63c-d11874201dee","trusted":true,"editable":false,"deletable":false},"source":["### ®[5] Task `token2nrep` and `nrep2token`\nCreate two dictionaries: one mapping vocabulary characters to numbers, named `token2nrep`, and another from numbers to tokens, named `nrep2token`. \n\n_Python pro-tip:_ `enumerate` is a lovely construct\n```null\nfor index, value in enumerate(L):\n    # do something\n```\n\n_Python pro-tip:_ dictionary comprehensions are a thing!\n```null\nchar2idx = {??? for x in L)\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"80242264-bce9-44d6-b63c-d11874201dee","trusted":true,"editable":false,"deletable":false},"source":["for index, value in enumerate(L):\n    # do something\n\nchar2idx = {??? for x in L)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 4"]},{"cell_type":"markdown","metadata":{"prismiaId":"d5792436-8735-4207-898d-ac35e926589e","trusted":true,"editable":false,"deletable":false},"source":["### ®[30] Task: Text Dataset design\nThe tf.data api provides a scalable way to to this. You need to:\n1. Create a `Dataset` of `text2nrep('text')` using the `from_tensor_slices` constuctor.\n2. Use the `window` method to configure a 'dataset of datasets', where each window returned is **always** of length `seq_length+1`. (see `drop_remanider`)\n3. Use `flat_map` and the provided `sub_to_batch` function to flatten the window dataset of datasets into a sequential data set containing sequential overlapping windows of text.\n4. Use `map` method, and the `split_input_target` method to split these sequences into appropriate (X input, y target) pairs\n"]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 5"]},{"cell_type":"markdown","metadata":{"prismiaId":"cdd3dee1-4b87-4a40-8481-c22e24222bc7","trusted":true,"editable":false,"deletable":false},"source":["### ®[10] Task: Batching with `tf.data`\nBelow is some code to shuffle and batch using `create_seq_data`. Answer the following in Prismia:\n1. How many batches of data are created per epoch? Is any data unused? Explain.\n2. More generally, add an explanation of what the parameters SEQ_LENGTH, BUFFER_SIZE, BATCH_SIZE are doing.\n3. Below we are shuffling and then batching. Explain what happens if instead, you shuffle after you batch. \n4. In general, when training, should you shuffle and then batch, or batch and then shuffle? \n\n\nhints: Use `nrep2text` to get a clearer picture of what is happening.  If you are still confused, try uncommenting the alternate `# test_text` variable.\n"]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 6"]},{"cell_type":"markdown","metadata":{"prismiaId":"c5f71864-5800-405a-b430-d6c9ef90aca2","trusted":true,"editable":false,"deletable":false},"source":["### ®[10] Task Understanding Parameterized Models\nAdd a comment for each parameter in the parameter dictionary above, paste a copy to Prismia as well. Your answer should look something like this:\n```null\np = {\n     'EMBEDDING_dim':100     # short comment\n    ,'GRU_units':1024        # short comment\n    ,'LSTM_units':0          # ...\n    ,'VOCAB_size':vocab_size # \n    ,'BUFFER_size':1000      #\n    ,'SEQUENCE_length':100   #\n    ,'BATCH_size':32         #\n    ,'BATCH_per_epoch':100   #\n    ,'CORPUS_fraction':.01   #\n    }\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"c5f71864-5800-405a-b430-d6c9ef90aca2","trusted":true,"editable":false,"deletable":false},"source":["p = {\n     'EMBEDDING_dim':100     # short comment\n    ,'GRU_units':1024        # short comment\n    ,'LSTM_units':0          # ...\n    ,'VOCAB_size':vocab_size # \n    ,'BUFFER_size':1000      #\n    ,'SEQUENCE_length':100   #\n    ,'BATCH_size':32         #\n    ,'BATCH_per_epoch':100   #\n    ,'CORPUS_fraction':.01   #\n    }"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 7"]},{"cell_type":"markdown","metadata":{"prismiaId":"46933baa-9db5-40d2-bd38-20be6fb22c62","trusted":true,"editable":false,"deletable":false},"source":["### ®[10] Task: [Tabula rasa](https://en.wikipedia.org/wiki/Tabula_rasa)\nTry running the cell below with the set_weights commented out and also uncommented.  Explain what you see in Prismia.  Include copy-and-paste examples of both runs.\n"]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 8"]},{"cell_type":"markdown","metadata":{"prismiaId":"bf5d032c-d9cd-4eb8-a4b0-cda829d8c539","trusted":true,"editable":false,"deletable":false},"source":["### ®[30] Task: Research Question\nThe synthetic tweets results are very impressive when you first see them. But if you re-run  `generate_text` multiple times, the results start to seem very familiar.  Try and figure out why this is the case, then try and figure out a way to improve the results.  \n\nDocument your efforts in the last Prismia problem.  Do not spend more than a couple of hours on this.  \n\nIf you create some impressive or particularly funny output, please consider posting to the Piazza hw6 [Fake Tweet Fun](https://piazza.com/class/kjj6m8xbzbp141?cid=238) thread.  \n\nWe are much more interested in you exploring the experimental setup and parameter approach available used in this notebook, than in creating a better solution to this toy problem.\n"]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 9"]}]}