{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0,"cells":[{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 1"]},{"cell_type":"markdown","metadata":{"prismiaId":"a58bd10e-3fc8-419f-997c-b9e35af90bb2"},"source":["### The Vanishing Gradient Problem\nLet's begin by investigating to what extent a proper choice of an activation function and weight initialization can mitigate the vanishing gradient problem. Consider the following toy data set:\n\n```python\nfrom sklearn.datasets import make_moons, make_circles, make_blobs\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\nnp.random.seed(42)\n\nX, y = make_circles(n_samples=1000 , noise=0.08, random_state=1)\nscaler = MinMaxScaler(feature_range=(-1, 1))\nX = scaler.fit_transform(X)\n\nfig, ax = plt.subplots(figsize=(8, 8))\nfor i in range(2):\n  samples_i = np.asarray(y == i)\n  ax.scatter(X[samples_i, 0], X[samples_i, 1], label=str(i))\n\nax.legend()\nax.set_aspect(1)\n```\nWhen you run this cell, the output should looks similar to this:![](https://firebasestorage.googleapis.com/v0/b/prismia.appspot.com/o/user-images%252Fimage-35be2dfd-ce7d-49ba-b878-0c797e088ec9.png?alt=media&token=9712a25b-0c69-409c-b05e-9465241653be)\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"a58bd10e-3fc8-419f-997c-b9e35af90bb2"},"source":["from sklearn.datasets import make_moons, make_circles, make_blobs\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\nnp.random.seed(42)\n\nX, y = make_circles(n_samples=1000 , noise=0.08, random_state=1)\nscaler = MinMaxScaler(feature_range=(-1, 1))\nX = scaler.fit_transform(X)\n\nfig, ax = plt.subplots(figsize=(8, 8))\nfor i in range(2):\n  samples_i = np.asarray(y == i)\n  ax.scatter(X[samples_i, 0], X[samples_i, 1], label=str(i))\n\nax.legend()\nax.set_aspect(1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"6fe7a668-d6a4-47e7-9ca1-c73ca71de90c"},"source":["Let's do our train-test split and define a plot_results function to display the results of model training runs.\n```python\n# Train test split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, train_size=.8, random_state=42)\n# Remark: the sklearn train_test_split functions randonmly shuffles the data\n# before doing the specified split.  It is good practice to do this.\n\n\ndef plot_training(model):\n  history = model.fit(\n    X_train, y_train,\n    validation_data=(X_test, y_test),\n    epochs=300,\n    verbose=0\n  )\n\n\n\n  _, train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n  _, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n  print('Train: %.2f, Test: %.2f' % (train_accuracy, test_accuracy))\n\n\n\n  print(history.history.keys())\n\n\n\n  plt.plot(history.history['accuracy'], label='train_accuracy')\n  plt.plot(history.history['val_accuracy'], label='val_accuracy')\n  plt.legend()\n\n'done!'\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"6fe7a668-d6a4-47e7-9ca1-c73ca71de90c"},"source":["# Train test split\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, train_size=.8, random_state=42)\n# Remark: the sklearn train_test_split functions randonmly shuffles the data\n# before doing the specified split.  It is good practice to do this.\n\n\ndef plot_training(model):\n  history = model.fit(\n    X_train, y_train,\n    validation_data=(X_test, y_test),\n    epochs=300,\n    verbose=0\n  )\n\n\n\n  _, train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n  _, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n  print('Train: %.2f, Test: %.2f' % (train_accuracy, test_accuracy))\n\n\n\n  print(history.history.keys())\n\n\n\n  plt.plot(history.history['accuracy'], label='train_accuracy')\n  plt.plot(history.history['val_accuracy'], label='val_accuracy')\n  plt.legend()\n\n'done!'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"46186a0a-ae43-4bca-ab2b-4813f66a5aa3"},"source":["Now let's build and train a not-so-good model.\n```python\n# Build a basic MLP\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Dense\n\nkeras.backend.clear_session()\nnp.random.seed(42)\ntf.random.set_seed(42)\n\nmodel = keras.models.Sequential()\ninit = keras.initializers.RandomUniform(minval=-1, maxval=1)\n\nfor i in range(3):\n  model.add(Dense(5, \n            activation='tanh',\n            kernel_initializer=init))\n\nmodel.add(Dense(1, activation='sigmoid', kernel_initializer=init))\n\nmodel.compile(\n    loss='binary_crossentropy', \n    optimizer=\"sgd\", \n    metrics=['accuracy']\n)\n\n\n\nplot_training(model)\nmodel.summary()\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"46186a0a-ae43-4bca-ab2b-4813f66a5aa3"},"source":["# Build a basic MLP\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Dense\n\nkeras.backend.clear_session()\nnp.random.seed(42)\ntf.random.set_seed(42)\n\nmodel = keras.models.Sequential()\ninit = keras.initializers.RandomUniform(minval=-1, maxval=1)\n\nfor i in range(3):\n  model.add(Dense(5, \n            activation='tanh',\n            kernel_initializer=init))\n\nmodel.add(Dense(1, activation='sigmoid', kernel_initializer=init))\n\nmodel.compile(\n    loss='binary_crossentropy', \n    optimizer=\"sgd\", \n    metrics=['accuracy']\n)\n\n\n\nplot_training(model)\nmodel.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"295ab002-fb7e-48ef-aa34-80222f5f9b44"},"source":["Using a Bayes classifier for this dataset has an accuracy of about 88%.  The accuracy values we got above are nowhere near this value.  The performance chart from the previous cell may look something like the following (the key point is that performance is bad):\n\n![](https://firebasestorage.googleapis.com/v0/b/prismia.appspot.com/o/user-images%252Fimage-6a1734a7-0a2c-4e19-ad0d-b9964c25bc0d.png?alt=media&token=aee7b420-f61d-412c-94aa-841cb7d7888d)\n® In the solution cell below, make a version of the code above, change the inner layer activation function(s) to something more appropriate, and the initialization method to make the model more easily trainable. You can also, try using a different optimizer.  \n\nYour final output should look something like this:\n\n![](https://cdn.mathpix.com/snip/images/s18OCim_ftu0EiMTzSf6XAUpeYxc8ENWsjjNPXPt8_Y.original.fullsize.png)\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"460ca204-0466-435e-807a-28a714f8dfd0"},"source":["```python\nkeras.backend.clear_session()\nnp.random.seed(42)\ntf.random.set_seed(42)\n\n\nmodel = keras.models.Sequential()\ninit = keras.initializers.HeNormal(seed=42)\n\n\nfor i in range(3):\n  model.add(Dense(5, activation='relu', kernel_initializer=init))\n\n\nmodel.add(Dense(1, activation='sigmoid', kernel_initializer=init))\n\n\nmodel.compile(\n    loss='binary_crossentropy', \n    optimizer=\"adam\", \n    metrics=['accuracy']\n)\n\n\nplot_training(model)\nmodel.summary()\n```\nI got both train and test accuracy 0.87 in the end the graph as above. The initialization method I use is HeNormal and activation function I use for inner layers is \"relu\".\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"460ca204-0466-435e-807a-28a714f8dfd0"},"source":["keras.backend.clear_session()\nnp.random.seed(42)\ntf.random.set_seed(42)\n\n\nmodel = keras.models.Sequential()\ninit = keras.initializers.HeNormal(seed=42)\n\n\nfor i in range(3):\n  model.add(Dense(5, activation='relu', kernel_initializer=init))\n\n\nmodel.add(Dense(1, activation='sigmoid', kernel_initializer=init))\n\n\nmodel.compile(\n    loss='binary_crossentropy', \n    optimizer=\"adam\", \n    metrics=['accuracy']\n)\n\n\nplot_training(model)\nmodel.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 2"]},{"cell_type":"markdown","metadata":{"prismiaId":"aa3bb81f-4478-4ba7-a001-c553d39aef34"},"source":["## Learning Rates & Schedules\n_Learning rate selection is more of an art than a science. The learning rate may be chosen by trial and error, but it is usually best to choose it by monitoring learning curves that plot the objective function as a function of time. This is more of an art than a science, and most guidance on this subject should be regarded with some skepticism._ -  Goodfellow et al., [Deep Learning, 2016](https://www.deeplearningbook.org/)\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"8823e8f7-a457-4c80-aebb-e7b9c11aaa63"},"source":["#### Understanding Learning Rate\n® Summarize the approach suggested in [this article](https://machinelearningmastery.com/understand-the-dynamics-of-learning-rate-on-deep-learning-neural-networks/) for selecting an initial learning rate.  \n\nAlso, explain what learning rate scheduling is, and four different approaches to learning rate scheduling.  Which ones are built into `keras` or `tf.keras`?\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"82cdd24d-ec60-45a1-9c93-26c48eb1669b"},"source":["A learning rate too large may converge to a suboptimal solution but a learning rate too small may converge too slow. We should tune the learning rate and use optimizer to optimize the learning rate during training based on time, epochs, learning rate itself.\nThe function \"ReduceLROnPlateau\" is built into keras and can be set as a callback funciton in \"fit()\". Also, you can define your own function to modify learning rate during training process using \"LearningRateScheduler\" in keras. The other three built-in optimizers are \"RMSProp\", \"Adagrad\" and \"Adam\".\n"]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 3"]},{"cell_type":"markdown","metadata":{"prismiaId":"6d381818-3299-4d6b-9a0b-ff2af4aa2b21"},"source":["### Turn on your GPU\nTraining deep networks is computationally demanding, and the sessions that run in Binder are not beefy enough for doing it seriously. Most crucially, they do not allow access to a GPU, and your laptop probably doesn't either (for sure it doesn't if you have a Mac; if you have a PC then maybe).\n\nTherefore, for the remainder of the homework we're going to switch to Colab for compute. This Google product offers free basic GPU access, and we recommend considering the purchase of Colab Pro for $10 a month to give upgraded RAM and better GPUs.\n\nThe easiest way to do this is to click on the help icon (top right corner of this window) and download this assignment as a Jupyter notebook. Then go to [colab.research.google.com](https://colab.research.google.com) and click \"Upload\" (right edge of the orange navigation bar), and select the downloaded notebook.\n\nMake sure after you open the notebook that you **switch to Runtime that includes a GPU**. To do so, click `Colab:Runtime -> Change Runtime Type` and choose GPU as your Hardware Accelerator.\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"06b70ea7-81ea-499a-ada1-e23f35be3fe3"},"source":["To check that you have successfully switched your runtime to include a GPU, you can utilize NVIDIA's System Management Interface, or NVIDIA SMI.\n```python\n!nvidia-smi\n```\n\nIf you see a GPU \"0\", then you have a GPU! Congrats! (devices are indexed starting from 0.) (You want to be looking at the line just below the line of equals  signs). I have a\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"06b70ea7-81ea-499a-ada1-e23f35be3fe3"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"d1ee4991-d7e3-4009-8045-1d1cd0c6517b"},"source":["### Network and dataset\nThe code below defines a simple CNN classifier for the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).\n```python\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\n\nnum_classes = 10\n\n# The data, split between train and test sets:\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\n\ndef get_model():\n  model = Sequential()\n  model.add(Conv2D(32, (3, 3), padding='same',\n                  input_shape=x_train.shape[1:]))\n  model.add(Activation('relu'))\n  model.add(Conv2D(32, (3, 3)))\n  model.add(Activation('relu'))\n  model.add(MaxPooling2D(pool_size=(2, 2)))\n  model.add(Dropout(0.25))\n\n  model.add(Conv2D(64, (3, 3), padding='same'))\n  model.add(Activation('relu'))\n  model.add(Conv2D(64, (3, 3)))\n  model.add(Activation('relu'))\n  model.add(MaxPooling2D(pool_size=(2, 2)))\n  model.add(Dropout(0.25))\n\n  model.add(Flatten())\n  model.add(Dense(512))\n  model.add(Activation('relu'))\n  model.add(Dropout(0.5))\n  model.add(Dense(num_classes))\n  model.add(Activation('softmax'))\n\n  return model\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"d1ee4991-d7e3-4009-8045-1d1cd0c6517b"},"source":["from tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\n\nnum_classes = 10\n\n# The data, split between train and test sets:\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\n\ndef get_model():\n  model = Sequential()\n  model.add(Conv2D(32, (3, 3), padding='same',\n                  input_shape=x_train.shape[1:]))\n  model.add(Activation('relu'))\n  model.add(Conv2D(32, (3, 3)))\n  model.add(Activation('relu'))\n  model.add(MaxPooling2D(pool_size=(2, 2)))\n  model.add(Dropout(0.25))\n\n  model.add(Conv2D(64, (3, 3), padding='same'))\n  model.add(Activation('relu'))\n  model.add(Conv2D(64, (3, 3)))\n  model.add(Activation('relu'))\n  model.add(MaxPooling2D(pool_size=(2, 2)))\n  model.add(Dropout(0.25))\n\n  model.add(Flatten())\n  model.add(Dense(512))\n  model.add(Activation('relu'))\n  model.add(Dropout(0.5))\n  model.add(Dense(num_classes))\n  model.add(Activation('softmax'))\n\n  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"14e17f9b-1efb-4a18-88ff-5428d0ab377e"},"source":["### Selecting a learning rate\n® Try training the above model using 4 rates over a geometric range from $10^{-5}$ to $10^{-1}$, using  `RMSProp` and shuffling. In the last line of your solution state what you think the best rate is as a comment.\n\nWhile exploring the optimal learning rate, keep in mind this competing advice from the textbook and this advice from _Deep Learning_:\n> Typically, the optimal initial learning rate, in terms of total training time and the ﬁnal cost value, is higher than the learning rate that yields the best performance after the ﬁrst 100_ iterations or so. Therefore, it is usually best to monitor the ﬁrst several iterations and use a learning rate that is higher than the best-performing learning rate at this time, but not so high that it causes severe instability. _Or when you don't have so much compute, 3 iterations. :-)\n"]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 4"]},{"cell_type":"markdown","metadata":{"prismiaId":"bee5a2da-1ae4-4276-9623-8d157fc56bfa"},"source":["### Learning Rate Schedules\nAfter choosing a good rate above, use **exponential scheduling** to decrease the learning rate while training until the model achieves the good accuracy on the test set.  Run for 20 epochs. Include early stopping with `patience=5`.\n\n**IMPORTANT**: save the weights of the final model, we will use them in the next problem. The following code fragment is one way to achieve this:\n```python\ndef save_model(model):\n  import os\n  model_name = 'keras_cifar10_trained_model.h5'\n  save_dir = os.path.join(os.getcwd(), 'saved_models')\n  \n  # Save model and weights\n  if not os.path.isdir(save_dir):\n      os.makedirs(save_dir)\n  model_path = os.path.join(save_dir, model_name)\n  model.save(model_path)\n  print('Saved trained model at %s ' % model_path)\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"bee5a2da-1ae4-4276-9623-8d157fc56bfa"},"source":["def save_model(model):\n  import os\n  model_name = 'keras_cifar10_trained_model.h5'\n  save_dir = os.path.join(os.getcwd(), 'saved_models')\n  \n  # Save model and weights\n  if not os.path.isdir(save_dir):\n      os.makedirs(save_dir)\n  model_path = os.path.join(save_dir, model_name)\n  model.save(model_path)\n  print('Saved trained model at %s ' % model_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"85726cfb-97c1-4cba-9be1-5d7d69b4e2b8"},"source":["## Transfer learning\nThe previous model was trained on 10 different classes.  It took quite a bit of time to train.\n\nIn this exercise, use **transfer learning** to create a new classifier for the following categories\n- cars (label 1) \n- cats (label 3)\n- trucks (label 9)\n- other (labels 2, 4, 5, 6, 7, 8). \n\n\nThe code below does an appropriate relabeling of the `y` variable and assigns it to the variable `y4` .\n```python\n# The data, split between train and test sets:\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\nnum_classes = 4\n\ndef label_map(label):\n  label_dict = {1: 0, 3: 1, 9: 2}\n  return label_dict.get(label, 3)\n\ny4_train = np.array([label_map(label) for label in y_train.ravel()])\ny4_test = np.array([label_map(label) for label in y_test.ravel()])\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"85726cfb-97c1-4cba-9be1-5d7d69b4e2b8"},"source":["# The data, split between train and test sets:\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\nnum_classes = 4\n\ndef label_map(label):\n  label_dict = {1: 0, 3: 1, 9: 2}\n  return label_dict.get(label, 3)\n\ny4_train = np.array([label_map(label) for label in y_train.ravel()])\ny4_test = np.array([label_map(label) for label in y_test.ravel()])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"22e10788-7b5a-47b9-9869-d6e5487b79ee"},"source":["You could just use the classifier from the previous part, however, this classifier was trained to do a more difficult task of distinguishing 10 classes. We hope that we can do better if we develop a classifier only to distinguish 4 classes. On the other hand, we don't want to train our new model from scratch. \n\n® The solution is to reuse layers (specifically, the convolutional ones) of the previous model. To do so, freeze the convolutional layers and train the model on your new, modified data set for approximately 5-15 epochs. \n\n_Hint: You can use this to confirm which layers are currently trainable._\n```python\ndef check_trainable(model):\n  for layer in new_model.layers:\n    print(layer.trainable, layer)\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"22e10788-7b5a-47b9-9869-d6e5487b79ee"},"source":["def check_trainable(model):\n  for layer in new_model.layers:\n    print(layer.trainable, layer)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 5"]},{"cell_type":"markdown","metadata":{"prismiaId":"253f2de2-c282-4e6d-a827-791545170412"},"source":["### Unfreezing more layers\n® Try squeezing out some additional performance by next unfreezing the top two convolutional layers and train your model for further 5-15 epochs.  The textbook recommends a lower learning rate for this last step.\n"]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 6"]},{"cell_type":"markdown","metadata":{"prismiaId":"813b3a5e-0e46-473f-9271-46d7da8855e1"},"source":["### Compare Models\nCompare the performance of the original model and your `new_model`.  Which one performs better?  Include code for the comparison and your answer below.\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"a74ad992-4693-4641-8e99-8519db17b747"},"source":["### Visualizations with Tensorboard\nThis week we'll continue working with TensorBoard. Let's begin by getting it set up.\n```python\n#imports\nimport tensorflow as tf\nimport numpy as np\nfrom sklearn.datasets import make_circles\nfrom matplotlib import pyplot\nimport tensorflow.keras as keras\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential\n\n# setup tensorboard, directories\n!rm -rf ./logs\n!mkdir ./logs/\n!mkdir ./logs/hw2\n\nlog_dir=\"./logs/hw2/\"\ndef tensorboard_callback(exp_name):\n  return tf.keras.callbacks.TensorBoard(log_dir=log_dir + exp_name, profile_batch=0, histogram_freq=1)\n# launch tensorboard with specific directory\n%load_ext tensorboard\n%tensorboard --logdir logs/hw2 \n```\n\nIf this cell hangs when you first execute it, and you do not see any output, please interrupt execution and run it again.\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"a74ad992-4693-4641-8e99-8519db17b747"},"source":["#imports\nimport tensorflow as tf\nimport numpy as np\nfrom sklearn.datasets import make_circles\nfrom matplotlib import pyplot\nimport tensorflow.keras as keras\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Sequential\n\n# setup tensorboard, directories\n!rm -rf ./logs\n!mkdir ./logs/\n!mkdir ./logs/hw2\n\nlog_dir=\"./logs/hw2/\"\ndef tensorboard_callback(exp_name):\n  return tf.keras.callbacks.TensorBoard(log_dir=log_dir + exp_name, profile_batch=0, histogram_freq=1)\n# launch tensorboard with specific directory\n%load_ext tensorboard\n%tensorboard --logdir logs/hw2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"113c23b4-f407-447c-99b6-194cce0c30c9"},"source":["## Regularization\nIn this problem you will experiment `l1` and `l2` layer regularization and early stopping for neural nets.\n\nConsider the following toy data set.\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"60148545-35e0-486c-8612-2cf2b414957f"},"source":["```python\nX, y = make_circles(n_samples=600, noise=0.25, random_state=0, factor=0.5)\nX_train, X_other = X[:200], X[200:]\ny_train, y_other = y[:200], y[200:]\n\nX_valid, X_test = X_other[:200], X_other[200:]\ny_valid, y_test = y_other[:200], y_other[200:]\n\ncolors = ['blue' if label == 1 else 'red' for label in y]\npyplot.scatter(X[:,0], X[:,1], color=colors)\n```\n\nRun the code below to show that the proposed model overfits the data.\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"60148545-35e0-486c-8612-2cf2b414957f"},"source":["X, y = make_circles(n_samples=600, noise=0.25, random_state=0, factor=0.5)\nX_train, X_other = X[:200], X[200:]\ny_train, y_other = y[:200], y[200:]\n\nX_valid, X_test = X_other[:200], X_other[200:]\ny_valid, y_test = y_other[:200], y_other[200:]\n\ncolors = ['blue' if label == 1 else 'red' for label in y]\npyplot.scatter(X[:,0], X[:,1], color=colors)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"c628a055-4660-40fb-b30c-55bb02eec5b3"},"source":["```python\ndef get_model():\n  init = keras.initializers.glorot_uniform(seed=66)\n  tf.random.set_seed(0)\n  \n  model = Sequential()\n  model.add(Dense(20, input_dim=2, activation='relu', kernel_initializer=init))\n  for i in range(6):\n    model.add(Dense(20, activation='relu', kernel_initializer=init))\n  model.add(Dense(1, activation='sigmoid'))\n  return model\n\nmodel = get_model()\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    verbose=0, \n    epochs=1000, \n    batch_size=32,\n    validation_data = (X_valid, y_valid),\n    callbacks=[tensorboard_callback('hw2.4-baseline')]\n)\n\n\ndef plot_decision_boundary(X, y, model, steps=100, cmap='Paired'):\n  cmap = pyplot.get_cmap(cmap)\n  \n  # Define region of interest by data limits\n  xmin, xmax = X[:,0].min() - 1, X[:,0].max() + 1\n  ymin, ymax = X[:,1].min() - 1, X[:,1].max() + 1\n  steps = 100\n  x_span = np.linspace(xmin, xmax, steps)\n  y_span = np.linspace(ymin, ymax, steps)\n  xx, yy = np.meshgrid(x_span, y_span)\n  \n  # Make predictions across region of interest\n  labels = np.rint(model.predict(np.c_[xx.ravel(), yy.ravel()]))\n  z = labels.reshape(xx.shape)\n  \n  fig, ax = pyplot.subplots(figsize=(16, 12), dpi=80,)\n  ax.contourf(xx, yy, z, cmap=cmap, alpha=0.5)\n  \n  train_labels = model.predict(X)\n  ax.scatter(X[:,0], X[:,1], c=y, cmap=cmap, lw=0)\n  \n  return fig, ax\n\nplot_decision_boundary(X, y, model, cmap='RdBu')\n\n_, train_accuracy = model.evaluate(X_train, y_train, callbacks=[])\n_, valid_accuracy = model.evaluate(X_valid, y_valid, callbacks=[])\n_, test_accuracy = model.evaluate(X_test, y_test, callbacks=[])\n\nprint(\"final training accuracy:\", train_accuracy)\nprint(\"final validation accuracy:\", valid_accuracy)\nprint(\"final test accuracy:\", test_accuracy)\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"c628a055-4660-40fb-b30c-55bb02eec5b3"},"source":["def get_model():\n  init = keras.initializers.glorot_uniform(seed=66)\n  tf.random.set_seed(0)\n  \n  model = Sequential()\n  model.add(Dense(20, input_dim=2, activation='relu', kernel_initializer=init))\n  for i in range(6):\n    model.add(Dense(20, activation='relu', kernel_initializer=init))\n  model.add(Dense(1, activation='sigmoid'))\n  return model\n\nmodel = get_model()\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    verbose=0, \n    epochs=1000, \n    batch_size=32,\n    validation_data = (X_valid, y_valid),\n    callbacks=[tensorboard_callback('hw2.4-baseline')]\n)\n\n\ndef plot_decision_boundary(X, y, model, steps=100, cmap='Paired'):\n  cmap = pyplot.get_cmap(cmap)\n  \n  # Define region of interest by data limits\n  xmin, xmax = X[:,0].min() - 1, X[:,0].max() + 1\n  ymin, ymax = X[:,1].min() - 1, X[:,1].max() + 1\n  steps = 100\n  x_span = np.linspace(xmin, xmax, steps)\n  y_span = np.linspace(ymin, ymax, steps)\n  xx, yy = np.meshgrid(x_span, y_span)\n  \n  # Make predictions across region of interest\n  labels = np.rint(model.predict(np.c_[xx.ravel(), yy.ravel()]))\n  z = labels.reshape(xx.shape)\n  \n  fig, ax = pyplot.subplots(figsize=(16, 12), dpi=80,)\n  ax.contourf(xx, yy, z, cmap=cmap, alpha=0.5)\n  \n  train_labels = model.predict(X)\n  ax.scatter(X[:,0], X[:,1], c=y, cmap=cmap, lw=0)\n  \n  return fig, ax\n\nplot_decision_boundary(X, y, model, cmap='RdBu')\n\n_, train_accuracy = model.evaluate(X_train, y_train, callbacks=[])\n_, valid_accuracy = model.evaluate(X_valid, y_valid, callbacks=[])\n_, test_accuracy = model.evaluate(X_test, y_test, callbacks=[])\n\nprint(\"final training accuracy:\", train_accuracy)\nprint(\"final validation accuracy:\", valid_accuracy)\nprint(\"final test accuracy:\", test_accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"f7cd729a-de97-491c-aec9-fb382c7673b4"},"source":["Over the next few problems, we'll implement the following regularization techniques:\n\n- early stopping\n- $l_1$ regularization\n- $l_2$ regularization\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"07e17488-c06c-4448-bbe0-f28cdefeddb6"},"source":["® Implement early stopping for the dataset and neural network above. Assess whether the model is still overfitting and comment on the shape of the decision boundary.\n"]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 7"]},{"cell_type":"markdown","metadata":{"prismiaId":"10459cdd-6e79-496f-bcb0-83f94e079509"},"source":["® Implement $l_1$ regularization for the dataset and neural network above. Assess whether the model is still overfitting and comment on the shape of the decision boundary.\n"]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 8"]},{"cell_type":"markdown","metadata":{"prismiaId":"82d7e4a4-941a-415f-bbf0-c95a52379821"},"source":["® Implement $l_2$ regularization for the dataset and neural network above. Assess whether the model is still overfitting and comment on the shape of the decision boundary.\n"]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 9"]},{"cell_type":"markdown","metadata":{"prismiaId":"45e5a05a-2d13-4d64-bb8b-f78d32effa9c"},"source":["You also can save your Tensorboard to a custom web link using [TensorBoard.dev](https://tensorboard.dev/):\n\n```python\n!tensorboard dev upload \\\n  --logdir logs \\\n  --name \"DATA1010 hw experiments\" \\\n  --description \"Each hw in its own sub-directory\"\n  --one_shot\n```\n\nAnd what's great about this is that the window will also graph your other models as long as your store them properly and then upload them using the command above. \n\nWhen you run this cell, answer the yes/No prompt and authenticate.  It will take 3 or 4 minutes to transfer all of the training logs to Tensorboard.dev.\n\n®  Provide a link to the resulting tensorboard.dev website for the hw2 experiments that used the tensorboard callback.\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"45e5a05a-2d13-4d64-bb8b-f78d32effa9c"},"source":["!tensorboard dev upload \\\n  --logdir logs \\\n  --name \"DATA1010 hw experiments\" \\\n  --description \"Each hw in its own sub-directory\"\n  --one_shot"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 10"]},{"cell_type":"markdown","metadata":{"prismiaId":"2bd88de0-a32d-4217-8d77-060dd9b6f4f4"},"source":["## Conceptual problems\n® Consider the computational problem of training a multilayer perceptron. During forward propagation, we cache the activations computed at each layer. Why do we cache these values (as opposed to discarding them after they have been used to compute the next layer's activations)? Select the correct answer choice and explain.\n- (a) It is used to keep track of the hyperparameters that we are searching over, to speed up computation.\n- (b) We use it to pass variables computed during backward propagation to the corresponding forward propagation step. It contains useful values for forward propagation to compute activations. \n- (c) We use it to pass variables computed during forward propagation to the corresponding backward propagation step. It contains useful values for backward propagation to compute derivatives. \n- (d) It is used to cache the intermediate values of the cost function during training.\n"]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 11"]},{"cell_type":"markdown","metadata":{"prismiaId":"d76a11e8-be09-44a8-9e17-e33a8cafe121"},"source":["® Provide a brief conceptual explanation of (i) why deeper models might perform better and (ii) why they are more difficult to train.\n"]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 12"]},{"cell_type":"markdown","metadata":{"prismiaId":"b4980ccd-757e-4077-8df5-dbf5a056f7fc"},"source":["® What is the vanishing gradient problem, and why are some activating functions better for the vanishing gradient problem? Compare leaky ReLU, ReLU and the Sigmoid function.\n"]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 13"]},{"cell_type":"markdown","metadata":{"prismiaId":"58b70e18-17c7-43c2-addc-224b7e576000"},"source":["### Chain rule\n® The figure below illustrates a simple neural network that we looked at in DATA 1010. The goal of this network is to say for each point in the unit square whether it's to the left of the semicircle shown. For more explanation, check it out in the [gallery](https://prismia.chat/shared/gallery).\n\n- (a) Click the \"show best\" button to set the values of the parameters to a particular collection which was obtained by training this neural network. You can move the point around to see that the decision boundary for the prediction function is indeed quite close to the semicircle. Now, wiggle the green slider connecting the top neuron in the input layer to the top neuron in the hidden layer. How much does this affect the predicted yellow probability (the top post-softmax value shown in the output layer)? Can you use this information to exactly determine the derivative of the loss function with respect to this particular weight (without doing any calculations)?\n- (b) At the original input point (0.2, 0.3), there are two dead hidden-layer neurons. Does this mean that those neurons are dead for _every_ input point? Trying moving the point around within the square to investigate.\n- (c) Move the input point to approximately (0.85, 0.15). Wiggle the point left and right to change the value in the top input neuron. Along how many pathways in the computational graph does this change influence the value in the top _output_ neuron? Apply the chain rule to compute the the derivative of the logit printed in the top output neuron with respect to the top input neuron (for an input of (0.85, 0.15) and parameters set to the 'show best' values).\n\n\n_Note: for the last part, you don't need to frame the problem in symbolic mathematical terms to solve it. Think directly about how small changes propagate in the network. You can experiment with [this mathlet](https://prismia.chat/shared/9NY8-45CQ) if you want to think through propagation of small changes in a simpler context first._\n"]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 14"]}]}