{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "hw8-language-models-embeddings.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f9e54af180474a0e936ff0841ff4ba8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2c88df29280544b9badc2da90471a7db",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5ee26c43ec9049cf9037ae3847a376da",
              "IPY_MODEL_c88084601c8f46e0aa2778ebcf612f9b"
            ]
          }
        },
        "2c88df29280544b9badc2da90471a7db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ee26c43ec9049cf9037ae3847a376da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_24b24a91419d4b29901ece5eb8b3dafd",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_977ad7a7523d464697f499660c23f4e8"
          }
        },
        "c88084601c8f46e0aa2778ebcf612f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c4edb130a1624ab0b11d0156057abed4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 1.21MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7dc3e350c04547dd92e8746a7fbdab31"
          }
        },
        "24b24a91419d4b29901ece5eb8b3dafd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "977ad7a7523d464697f499660c23f4e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c4edb130a1624ab0b11d0156057abed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7dc3e350c04547dd92e8746a7fbdab31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "170f8b62e5144324b1a4be58e3a31f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8c46c1b7d53745e38e0d15181c87cd23",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_286c7391d16e40209a45238ad0cfd925",
              "IPY_MODEL_379cdc9ec74a4ee282f79984cd3563fe"
            ]
          }
        },
        "8c46c1b7d53745e38e0d15181c87cd23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "286c7391d16e40209a45238ad0cfd925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_82e7c029b2cf4d139828ac0f32d459cc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_71b4c461904848a6a9b26903b741837e"
          }
        },
        "379cdc9ec74a4ee282f79984cd3563fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fb896c53279a4466bdc3522b4dd83184",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:02&lt;00:00, 228kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_15073c6f43a74ad0a39b819de5237a5a"
          }
        },
        "82e7c029b2cf4d139828ac0f32d459cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "71b4c461904848a6a9b26903b741837e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb896c53279a4466bdc3522b4dd83184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "15073c6f43a74ad0a39b819de5237a5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad63254ded7440c4a714390ced26c8a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4c87941df7e246729319ae6a5b5a1f7f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1302c9fa336c4149bce70d22ba365079",
              "IPY_MODEL_11b60fa0816c4acd9ad85406cc44b047"
            ]
          }
        },
        "4c87941df7e246729319ae6a5b5a1f7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1302c9fa336c4149bce70d22ba365079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4ed780fa88904c6bb90845ac8a16e4c6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1355256,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1355256,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4dd3d396ca6947b79e43334b7c8183c2"
          }
        },
        "11b60fa0816c4acd9ad85406cc44b047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d6a2c54eaf33436a8aadfa0e7263238b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 2.41MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_60a165388ae149d193731fb417f798eb"
          }
        },
        "4ed780fa88904c6bb90845ac8a16e4c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4dd3d396ca6947b79e43334b7c8183c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d6a2c54eaf33436a8aadfa0e7263238b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "60a165388ae149d193731fb417f798eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d5e56a8e25646baac4ef781549ac5b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c5f7d90571a24216904349e83ac2dc73",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aff4d9bd09dc4de6b68dfae5ea89e52e",
              "IPY_MODEL_61bb07adf3ae4fa99f3751c697736151"
            ]
          }
        },
        "c5f7d90571a24216904349e83ac2dc73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aff4d9bd09dc4de6b68dfae5ea89e52e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_69b030776bd24bab8644c281c59548a4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 665,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 665,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6694ad368b054b2dac5f703f39bdfde1"
          }
        },
        "61bb07adf3ae4fa99f3751c697736151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d3c703f9fbd04892945548fb62fc55c8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 665/665 [00:00&lt;00:00, 2.46kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9957afadacda4584bb085909060439fe"
          }
        },
        "69b030776bd24bab8644c281c59548a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6694ad368b054b2dac5f703f39bdfde1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3c703f9fbd04892945548fb62fc55c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9957afadacda4584bb085909060439fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98f89d3d04bd49308ab52ea429a6665a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_18b7fc044c8f40899e9f02629fdb2650",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8fd1b6bc104d43fa9cd326f7755695e0",
              "IPY_MODEL_8226a40be2f34649a8e7539af35a3da2"
            ]
          }
        },
        "18b7fc044c8f40899e9f02629fdb2650": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8fd1b6bc104d43fa9cd326f7755695e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_20a43f77caf348aa8366f246c2556666",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 497933648,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 497933648,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_297282c91a8d4a2a93876739b6d4f2cf"
          }
        },
        "8226a40be2f34649a8e7539af35a3da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_74b1fe3bf93e4599bc872bd26d782a08",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 498M/498M [00:09&lt;00:00, 52.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cfcc8ae13aaf4df89ec0dd32e265fbac"
          }
        },
        "20a43f77caf348aa8366f246c2556666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "297282c91a8d4a2a93876739b6d4f2cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74b1fe3bf93e4599bc872bd26d782a08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cfcc8ae13aaf4df89ec0dd32e265fbac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaHeader": true,
        "id": "q6YBDCYZKpay"
      },
      "source": [
        "### Problem 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaId": "0097b3a5-15d4-4172-9822-7cfcc31cceef",
        "trusted": true,
        "editable": false,
        "deletable": false,
        "id": "Dm3u9Zk2Kpa4"
      },
      "source": [
        "# Introduction\n",
        "Many NLP models have HUGE numbers of parameters and are trained on VAST amounts of data. TopBot's [Leading NLP Language Models for 2020](https://www.topbots.com/leading-nlp-language-models-2020/) provides a small survey of some of the most popular ones.\n",
        "\n",
        "Because of this, unless your working in a research group with substantial resources, it is unlikely you will be training your models from scratch. The data requirements also mean that these pre-trained models are generally non-specific to a particular problem domain or task.\n",
        "\n",
        "Two key steps to building an effective NLP application are as follows:\n",
        "1. Figure out how to lever an existing Language Model to solve the problem at hand\n",
        "2. Improve the performance by judicious training\n",
        "\n",
        "In this homework, you will do the following:\n",
        "\n",
        "- Begin by reviewing some NLP resources and tasks\n",
        "- Learn how to use pre-trained hugging face models for Casual Language Modelling and Masked Language Modelling.\n",
        "- Fine-tune a model to a particular corpus\n",
        "- After that, you'll use some Language Model sampling methods similar to beam search to admire your handiwork\n",
        "- We'll wrap up with some fun but important \"semantic geometry\" examples at the end of this assignment.\n",
        "\n",
        "\n",
        "Please submit the results of this work to the [Prismia.chat](https://prismia.chat/projects/cba3b7ef-4b29-456d-985b-9f4bc5e495cb/edit-assignment/Prismia.chat) assignment using the same approach we have used before. Only copy code and results when asked or when they help support that narrative you create to demonstrate your learning and understanding.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaId": "16a86ce3-a557-4c4e-9291-102d3624718c",
        "trusted": true,
        "editable": false,
        "deletable": false,
        "id": "JHA8BSp8Kpa5"
      },
      "source": [
        "# NLP Resources and Project Data Resources\n",
        "**Q: There are so many different NLP tasks and resources. How can I learn about them and get started?**\n",
        "\n",
        "A: The Hugging Face [Task Summary](https://huggingface.co/transformers/task_summary.html) page includes descriptions of many common NLP tasks and high-level PyTorch and Tensorflow based code for running each type of task. The Open in Colab menu button will allow you to open this page as a colab notebook using your PyTorch or the Tensorflow framework. [The Big Table of Tasks](https://huggingface.co/transformers/examples.html#the-big-table-of-tasks) contains a similar listing of common NLP tasks with additional resources and code samples.\n",
        "\n",
        "**Q: Are there any easy-to-use NLP datasets or other machine learning datasets that would be a good starting point for my project?**\n",
        "\n",
        "A: The [Hugging Face datasets](https://huggingface.co/datasets) and [Tensorflow datasets](https://www.tensorflow.org/datasets) repositories contain large amounts of ready-to-use NLP data that you can easily import. Another good place to look for various data, all in a standardized format, is the [Fast.ai datasets](https://course.fast.ai/datasets) repository. Kaggle competition data is also a great place to get started since it allows you to compare your performance with world-class data modelers. AI and ML challenges are another great data resource. These also provide a good frame of reference for your efforts. (If someone finds or compiles a nice catalog of AI and ML challenges these, please let us know so we can add a link to it.) **Note:** The non-Hugging Face dataset recommendations cover a lot more than NLP data.\n",
        "\n",
        "**Q: Isn't Hugging Face a PyTorch library? Do I need to learn PyTorch to use it?**\n",
        "\n",
        "A: No, while it is true PyTorch is currently the primary research framework used for NLP research, and many Hugging Face examples are PyTorch specific, there are Tensorflow versions of many of their high-level components. See the Hugging Face [Task Summary](https://huggingface.co/transformers/task_summary.html) for some examples. This [Medium article](https://towardsdatascience.com/tensorflow-and-transformers-df6fceaf57cc) from James Briggs talks a bit about this issue and provides a no-nonsense, step-by-step sentiment analysis example. It also includes links to relevant articles on tf dataset configuration and optimizer configuration.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaId": "8353f87d-77d1-4285-8fcb-d84e81f8b70c",
        "trusted": true,
        "editable": false,
        "deletable": false,
        "id": "924eLqTMKpa6"
      },
      "source": [
        "### ®[10] Task: Your own table of common NLP Applications\n",
        "In a cell below, create a table that enumerates each of the common NLP tasks listed in [The Big Table of Tasks](https://huggingface.co/transformers/examples.html#the-big-table-of-tasks) at HuggingFace.co.\n",
        "\n",
        "1. Your table should provide a brief description of each task in your own words.\n",
        "2. An example of each task.\n",
        "3. A specific dataset that would be appropriate for exploring three or more of these NLP tasks. Please include a link to a webpage that describes the dataset and the steps needed to download and begin to use it. Ideally, these steps would be appropriate for use in colab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWNHmNeaKrn1"
      },
      "source": [
        "1. **language-modeling**, predict next token or a masked token in a sequence, Example: https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/language_modeling.ipynb, Dataset: https://github.com/huggingface/datasets/tree/master/datasets/wikitext\n",
        "2. **multiple-choice**, select most plausible choice in a multiple-choice question, Example: https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/multiple_choice.ipynb, Dataset: https://github.com/huggingface/datasets/tree/master/datasets/swag\n",
        "3. **question-answering**,  extracting the answer to a question from a given context, Example: https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/question_answering.ipynb, Dataset:https://github.com/huggingface/datasets/tree/master/datasets/squad_v2\n",
        "4. **summarization**, generate text for summarizing the give text, Example: https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/summarization.ipynb, Dataset: https://github.com/huggingface/datasets/tree/master/datasets/xsum\n",
        "5. **text-classification**, classify a sequence into a category of sentiment (usually 2 categories), Example: https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/text_classification.ipynb, Dataset: https://github.com/huggingface/datasets/tree/master/datasets/glue\n",
        "6. **text-generation**,generate long text sequence given a start sequence, Example: https://colab.research.google.com/github/huggingface/blog/blob/master/notebooks/02_how_to_generate.ipynb, Dataset: None\n",
        "7. **token-classification**, predict a label for token in a given sequence, Example: https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/token_classification.ipynb, Dataset: https://github.com/huggingface/datasets/tree/master/datasets/conll2003\n",
        "8. **translation**, translate sequences between 2 different languages, Example: https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/translation.ipynb, Dataset: http://www.statmt.org/wmt16/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaHeader": true,
        "id": "ur7XkmH0Kpa6"
      },
      "source": [
        "### Problem 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaId": "648d292a-329f-4b3e-9c14-abaf29d9eff5",
        "trusted": true,
        "editable": false,
        "deletable": false,
        "id": "11m8t69nKpa7"
      },
      "source": [
        "# Pretrained language models\n",
        "GPT2 is an example of a new high-performance Language Model. Please read this [article](https://openai.com/blog/better-language-models/) from its developers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaId": "1104c52e-9221-4063-86f7-f829207d1681",
        "trusted": true,
        "editable": false,
        "deletable": false,
        "id": "d0pSCyP1Kpa7"
      },
      "source": [
        "### ®[5] Task: What is GPT2\n",
        "Write a short description of the GPT2 model, in general. Include details on an interesting application or example. Be sure to cite the paper that originally introduced GPT and a reference for your application or example.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPPW76-5KwiW"
      },
      "source": [
        "GPT2 model is a unsupervised training transformer model, trained on large-scale dataset, that can complete tasks such as text-generation, question-answering, translation, summarization and text comprehension. For question-answering task, the model shows an interesting pattern that it did not answer the biggest state in America correctly. However it gives an answer that many people would give, which means GPT2 actually learns like human in some way through dataset and make mistakes like human makes.\n",
        "\n",
        "Citation: Radford, Alec, Wu, Jeffrey, Child, Rewon, Luan, David, Amodei, Dario and Sutskever, Ilya. \"Language Models are Unsupervised Multitask Learners.\" (2018): .\n",
        "\n",
        "Reference for application: https://openai.com/blog/better-language-models/#task3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaHeader": true,
        "id": "ynrm3mtZKpa8"
      },
      "source": [
        "### Problem 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaId": "f0b3675b-ed91-4e5c-ad30-31dbe6769b05",
        "trusted": true,
        "editable": false,
        "deletable": false,
        "id": "kSn99EqdKpa8"
      },
      "source": [
        "### ®[5] Task: Data and Society\n",
        "Explain issues and concerns associated with the widespread adoption of these models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWXolneDKy98"
      },
      "source": [
        "Author is afraid of malicoious use of this model. There are concerns about large language models being used to generate deceptive, biased, or abusive language at scale. Safety concerns is always the issue with machine learning and AI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaHeader": true,
        "id": "FnjaTqfZKpa8"
      },
      "source": [
        "### Problem 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaId": "da0eeaf5-275c-4c4a-ab05-e9db86edb09c",
        "trusted": true,
        "editable": false,
        "deletable": false,
        "id": "PznvuO5wKpa8"
      },
      "source": [
        "## Using pre-trained language models\n",
        "Run the Colab-Notebook associated with the **`[language-modeling]`** task in [The Big Table of Tasks](https://huggingface.co/transformers/examples.html#the-big-table-of-tasks), and work through it section by section. (The Big Table of Tasks has Tasks listed row by row,  where the name of each task is shown in the first column and the Colab notebook associated with each task is listed in the last column.)\n",
        "\n",
        "Adding these pip install commands at the beginning of the notebook will help you get started:\n",
        "\n",
        "```python\n",
        "! pip install -qq datasets\n",
        "! pip install -qq transformers\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "prismiaParentId": "da0eeaf5-275c-4c4a-ab05-e9db86edb09c",
        "trusted": true,
        "editable": false,
        "deletable": false,
        "id": "fFhy2JMgKpa9"
      },
      "source": [
        "! pip install -qq datasets\n",
        "! pip install -qq transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaId": "f481c67b-acab-4521-89d7-c89ecdc520d1",
        "trusted": true,
        "editable": false,
        "deletable": false,
        "id": "qzDWcPS1Kpa-"
      },
      "source": [
        "[(language_modeling.ipynb)](https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/language_modeling.ipynb)\n",
        "### ®[10] Task: Language Modelling 101\n",
        "1. Explain the difference between Causal Language Modelling and Masked Language Modelling.\n",
        "2. Why are the perplexity scores different between the two tasks as implemented in the notebook?\n",
        "3. Report and discuss the perplexity scores (using the fine-tuning validation data) pre-fine-tuning and post fine-tuning for both task types.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z3C31ulK378"
      },
      "source": [
        "1. The casual language modeling predict the last word based on previous sequence. The masked language modeling predicts based on the rest of the sentence.\n",
        "2. MLM task is easier than that of the CLM task.\n",
        "3. After fine-tuning, CLM model has perplexity score 38.17 and MLM model has perplexity score 6.37."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaHeader": true,
        "id": "CulujpD9Kpa-"
      },
      "source": [
        "### Problem 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaId": "576fccb7-4d8b-493d-aad9-5e2232a679f0",
        "trusted": true,
        "editable": false,
        "deletable": false,
        "id": "372yTpMaKpa-"
      },
      "source": [
        "[(language_modeling.ipynb)](https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/language_modeling.ipynb)\n",
        "\n",
        "**Instructor clarification:** autoencoder = actual model class for each task. [AutoModelForCasualLM](https://huggingface.co/transformers/model_doc/auto.html#automodelforcausallm) is just a wrapper class.\n",
        "\n",
        "### ®[15*] Task: Doing it your own way\n",
        "_*This problem is now entirely optional, if you do complete it, it will count upto 15 points towards a perfect score on the homework.  See Piazza for more details._\n",
        "1. Update the notebook to use a different model and a different training dataset (your choice).\n",
        "2. Provide a summary of your results below. Include details on the autoencoder used, and other choices made.\n",
        "3. What tokenizer is used?\n",
        "4. What fine-tuning training parameters did you use?\n",
        "5. Include before and after fine-tuning perplexities.\n",
        "6. Include example setups and outputs from each modelling task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaHeader": true,
        "id": "G8lij5ywKpa-"
      },
      "source": [
        "### Problem 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaId": "7132f138-3604-4e37-a5aa-8000fa49ff8f",
        "trusted": true,
        "editable": false,
        "deletable": false,
        "id": "T0wGCtA9Kpa_"
      },
      "source": [
        "### Tokenization\n",
        "TensorFlow and HuggingFace.co both support several popular tokenization approaches. Modern subword tokenization strategies handle word stemming and new words out of vocabulary words in an elegant way. Lena Voita's [exposition](https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html#bpe) on Byte Pair Encoding (BPE) is a great way to get started. Extensions to BPE form the basis for [Byte-level BPE](https://arxiv.org/pdf/1909.03341.pdf) and [Word Piece](https://paperswithcode.com/method/wordpiece) tokenizers used for the GPT and Bert models. These allow efficient encoding for unicode characters and emojis, whereas many other popular tokenizers replace unknown characters and words with <unk> tokens.\n",
        "\n",
        "Hugging face provides [support and clear summaries](https://huggingface.co/transformers/tokenizer_summary.html) for each of these tokenization approaches and several other cutting-edge approaches, including [Sentence Piece](https://paperswithcode.com/method/sentencepiece). If you are interested in working with languages that do not have a space between each word (like Chinese), you should read more about XLM and its generalization, SentencePiece.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaId": "568d1037-e349-4754-85ac-8aea6a358e76",
        "trusted": true,
        "editable": false,
        "deletable": false,
        "id": "4KYHorMQKpa_"
      },
      "source": [
        "### ®[5] Task: Pretrained model gotchas\n",
        "1. When working with pre-trained models, why do you need to use the same tokenizer that was originally used to create the pre-trained model? What would happen if you did not?\n",
        "2. In practice, word vectors are stored in an embedding layer in a neural network. Fine-tuning models with enough data improves performance. Explain why retraining word vectors may hurt our model if our training dataset is small and includes limited vocabulary.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5pEIkdJYowu"
      },
      "source": [
        "1. Since if we use different tokenizer, we might have have different tokens for the same word, which will break the logic between the model and the detokenization process.\n",
        "\n",
        "2. If our dataset is small, the word distribution and the relation between words will be biased comparing to the pre-trianed model's dataset. For exmaple, the \"bank\" which means the side of river may not exist in our small dataset, so the relationship and similiarity between words will be changed in our small dataset. Hence, it will hurt the perforamnce our the pre-trained model and our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaHeader": true,
        "id": "irpVb3djKpa_"
      },
      "source": [
        "### Problem 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaId": "4fefece4-3e38-4607-a9ef-ef0b9e00f751",
        "trusted": true,
        "editable": false,
        "deletable": false,
        "id": "yvhzEyOXKpbA"
      },
      "source": [
        "## Text Generation\n",
        "Thus far in the course, we have seen examples of Monte-Carlo sampling, greedy search, and Beam Search to look at different model outputs. [The Big Table of Tasks](https://huggingface.co/transformers/examples.html#the-big-table-of-tasks) **text-generation** notebook introduces several other methods.\n",
        "\n",
        "Please open this notebook work through it cell by cell, and fiddle with it so that you can understand the behavior.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaId": "b659bd3b-91b0-4c0b-87bf-82c46f4d0ccf",
        "trusted": true,
        "editable": false,
        "deletable": false,
        "id": "wb-9-RLKKpbA"
      },
      "source": [
        "[(02_how_to_generate.ipynb)](https://colab.research.google.com/github/huggingface/blog/blob/master/notebooks/02_how_to_generate.ipynb)\n",
        "### ®[15] Task: Greedy Stochastic Search\n",
        "In your own words explain the following as clearly as you can\n",
        "1. The scheme introduced that references [Paulus et al. (2017)](https://arxiv.org/abs/1705.04304) and [Klein et al. (2017)](https://arxiv.org/abs/1701.02810)\n",
        "2. The method of [Fan et al. (2018)](https://arxiv.org/pdf/1805.04833.pdf)\n",
        "3. The final method attributed to [Ari Holtzman et al. (2019)](https://arxiv.org/abs/1904.09751)\n",
        "\n",
        "Include the relevant Hugging Face API call. Include examples that are different from the ones given, +1 if they are amusing!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330,
          "referenced_widgets": [
            "f9e54af180474a0e936ff0841ff4ba8d",
            "2c88df29280544b9badc2da90471a7db",
            "5ee26c43ec9049cf9037ae3847a376da",
            "c88084601c8f46e0aa2778ebcf612f9b",
            "24b24a91419d4b29901ece5eb8b3dafd",
            "977ad7a7523d464697f499660c23f4e8",
            "c4edb130a1624ab0b11d0156057abed4",
            "7dc3e350c04547dd92e8746a7fbdab31",
            "170f8b62e5144324b1a4be58e3a31f39",
            "8c46c1b7d53745e38e0d15181c87cd23",
            "286c7391d16e40209a45238ad0cfd925",
            "379cdc9ec74a4ee282f79984cd3563fe",
            "82e7c029b2cf4d139828ac0f32d459cc",
            "71b4c461904848a6a9b26903b741837e",
            "fb896c53279a4466bdc3522b4dd83184",
            "15073c6f43a74ad0a39b819de5237a5a",
            "ad63254ded7440c4a714390ced26c8a5",
            "4c87941df7e246729319ae6a5b5a1f7f",
            "1302c9fa336c4149bce70d22ba365079",
            "11b60fa0816c4acd9ad85406cc44b047",
            "4ed780fa88904c6bb90845ac8a16e4c6",
            "4dd3d396ca6947b79e43334b7c8183c2",
            "d6a2c54eaf33436a8aadfa0e7263238b",
            "60a165388ae149d193731fb417f798eb",
            "6d5e56a8e25646baac4ef781549ac5b9",
            "c5f7d90571a24216904349e83ac2dc73",
            "aff4d9bd09dc4de6b68dfae5ea89e52e",
            "61bb07adf3ae4fa99f3751c697736151",
            "69b030776bd24bab8644c281c59548a4",
            "6694ad368b054b2dac5f703f39bdfde1",
            "d3c703f9fbd04892945548fb62fc55c8",
            "9957afadacda4584bb085909060439fe",
            "98f89d3d04bd49308ab52ea429a6665a",
            "18b7fc044c8f40899e9f02629fdb2650",
            "8fd1b6bc104d43fa9cd326f7755695e0",
            "8226a40be2f34649a8e7539af35a3da2",
            "20a43f77caf348aa8366f246c2556666",
            "297282c91a8d4a2a93876739b6d4f2cf",
            "74b1fe3bf93e4599bc872bd26d782a08",
            "cfcc8ae13aaf4df89ec0dd32e265fbac"
          ]
        },
        "id": "8q98RpqfK5vq",
        "outputId": "4537062b-3205-45bf-aac8-ab515d22a5fa"
      },
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# add the EOS token as PAD token to avoid warnings\n",
        "model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9e54af180474a0e936ff0841ff4ba8d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "170f8b62e5144324b1a4be58e3a31f39",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad63254ded7440c4a714390ced26c8a5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355256.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d5e56a8e25646baac4ef781549ac5b9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98f89d3d04bd49308ab52ea429a6665a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=497933648.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-Xb4zFOgktq",
        "outputId": "85d14e6a-de19-4bb2-a78b-30c3706779ac"
      },
      "source": [
        "input_ids = tokenizer.encode('I am a Brown DSI Student.', return_tensors='tf')\n",
        "beam_outputs = model.generate(\n",
        "    input_ids, \n",
        "    max_length=50, \n",
        "    num_beams=5, \n",
        "    no_repeat_ngram_size=2, \n",
        "    num_return_sequences=5, \n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "# now we have 3 output sequences\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "for i, beam_output in enumerate(beam_outputs):\n",
        "  print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "0: I am a Brown DSI Student. I am also a member of the Board of Trustees of Brown University.\n",
            "\n",
            "I have a Bachelor of Science degree from the University of California, Berkeley. My research interests include the intersection of science and technology\n",
            "1: I am a Brown DSI Student. I am also a member of the Board of Trustees of Brown University.\n",
            "\n",
            "I have a Bachelor of Science degree from the University of California, Berkeley. My research interests include the intersection of science, technology\n",
            "2: I am a Brown DSI Student. I am also a member of the Board of Trustees of Brown University.\n",
            "\n",
            "I have a Bachelor of Science degree from the University of California, Berkeley. My research interests include the intersection of psychology, sociology\n",
            "3: I am a Brown DSI Student. I am also a member of the Board of Trustees of Brown University.\n",
            "\n",
            "I have a Bachelor of Science degree from the University of California, Berkeley. My research interests are in the history of science and\n",
            "4: I am a Brown DSI Student. I am also a member of the Board of Trustees of Brown University.\n",
            "\n",
            "I have a Bachelor of Science degree from the University of California, Berkeley. My research interests are in the history of science,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzHkYiSgg7CF",
        "outputId": "f67d871f-d81c-4402-ee3d-c5996fdd74f1"
      },
      "source": [
        "sample_output = model.generate(\n",
        "    input_ids, \n",
        "    do_sample=True, \n",
        "    max_length=50, \n",
        "    top_k=40\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I am a Brown DSI Student. I worked as a full time teaching assistant in 2009 when I was sent an honorary degree that allowed my personal life under my direct supervision. The program taught students a set of fundamentals about why they should not get promoted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VpOj5O5h_l9",
        "outputId": "af980d22-13dd-4319-bcfe-fe294022e912"
      },
      "source": [
        "sample_output = model.generate(\n",
        "    input_ids, \n",
        "    do_sample=True, \n",
        "    max_length=50, \n",
        "    top_p=0.9, \n",
        "    top_k=0\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I am a Brown DSI Student. I also support the civil rights movement. In my class, I have talked with many Native American groups about their reservations. However, I never cared about my ethnicity, religious views, or any other factors. I\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhxEBufIZ38M"
      },
      "source": [
        "1. n-grams: It set the probability to zero if the next word within range of n-gram size has been seen before the current postiion. In the example we try above, the final research interest contain different contents.\n",
        "\n",
        "2. Top-K sampling: This gives some randomness to the next word instead of take the word with highest probability. The sampling rescale the probability distribution of the top-k words and sample from it. The second exmaple we try above generate a story about teaching , honoray degree which really surprises me but still stay within range of academic. It even gives some interesting details in the last sentence.\n",
        "\n",
        "3. Top-nucleus sampling: This is same method in 2 but with a different way to pick the set of words to resample. Instead of picking top fixed number of words, it picks top n words that reaches a probability threshold. So the number of words that are going to be sampled from is dynamic. It redirets the topic from Academic content to a personal introduction, which is different from the result of top-k sampling. It seems more surprising."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaHeader": true,
        "id": "Eg-K4RvVKpbA"
      },
      "source": [
        "### Problem 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaId": "9d3f2552-a8ab-4f6c-bd9f-0ed1ea6ae56c",
        "trusted": true,
        "editable": false,
        "deletable": false,
        "id": "MM20u2NuKpbB"
      },
      "source": [
        "# Word-Embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaId": "4b0543a9-4933-41d4-8da1-84043a866d9e",
        "trusted": true,
        "editable": false,
        "deletable": false,
        "id": "nSxG75YhKpbB"
      },
      "source": [
        "In this part of the assignment, you explore the crazy world of semantic geometry.\n",
        "- The [Tensorflow Embedding Projector](https://projector.tensorflow.org/) allows one to project high-dimensional word embeddings into a lower-dimensional space.\n",
        "\n",
        "\n",
        "**Instructor Note:**\n",
        "The initially released version of this assignment suggested this reading\n",
        "- Original Text: [The Geometry of Culture: Analyzing the Meanings of Class through Word Embeddings](https://doi.org/10.1177%2F0003122419877135) explore word embeddings through time.\n",
        "\n",
        "However, an earlier version of this paper is easier to follow for the purposes of this assignment (the figures are located at the very end of the pdf).\n",
        "- More Direct Text: [The Geometry of Culture: Analyzing Meaning through Word Embeddings](https://paperswithcode.com/paper/the-geometry-of-culture-analyzing-meaning)\n",
        "\n",
        "If you have not already answered the questions using the Original Text, please use the More Direct Text.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaId": "9a643364-2e66-44a4-9a29-da379ebae962",
        "trusted": true,
        "editable": false,
        "deletable": false,
        "id": "PalccSuHKpbB"
      },
      "source": [
        "[Embedding Projector](https://projector.tensorflow.org/)\n",
        "### ®[10] Task: A manual for new projectionists\n",
        "1. In your own words, clearly explain each projection type that is supported.\n",
        "2. Explain the other controls and give an example of how to use each one.\n",
        "\n",
        "You are welcome to use annotated screenshot (s) or other methods to do this concisely and efficiently.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQ67bvK3KR7U"
      },
      "source": [
        "1. A projection is a mapping from a high dimensional space to a low dimensional space that is injective and sturcture-preserving. Sturcture-preserving means that the original relationship between vectors in the high-dimensional space is preserved in the low dimensional space. It supports UMAP, T-SNE, PCA and custom. PCA is finding k orthogonal components that are linear combinations of some features that show the most variances. UMAP is mainfold approximation. T-SNE uses t-distribution to convert data similarity to probability and shrink the size of the vector space by minimizeing the Kullback-Leibler divergence between current vector space and original high dimensional space.\n",
        "\n",
        "2. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaHeader": true,
        "id": "3miYTZCmKpbB"
      },
      "source": [
        "### Problem 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaId": "bce4d17b-3be2-429b-9acb-5338c153a4ea",
        "trusted": true,
        "editable": false,
        "deletable": false,
        "id": "091IRlnmKpbB"
      },
      "source": [
        "[Embedding Projector](https://projector.tensorflow.org/)\n",
        "Use the Embedding Projector to find a [polysemous word](https://en.wikipedia.org/wiki/Polysemy) where similar words (according to cosine similarity) have multiple meanings.\n",
        "\n",
        "For example, the word \"spring\" can refer to either \"flower\" and \"suspension.\" The word \"tie\" can have associations with both \"shirt\" and \"football.\"\n",
        "\n",
        "You may need to try several polysemous word candidates before you find one that works.\n",
        "\n",
        "### ®[5] Task: Polysemous Word Hunt\n",
        "1. Please provide setup and output for 3 polysemous word(s) you discover.\n",
        "2. For each set of words, describe the multiple meanings that occur.\n",
        "3. Why do you think some polysemous words don't work?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlabmWCLso9f"
      },
      "source": [
        "1. I use PCA with Word2Vec dataset. My 3 words are fall, star, window\n",
        "2. Fall can refer to the falling movment or a season. It has close realtionship to grow and falling. Star has close relationship to trek and nba. It can refer to a astronomic object or a popular person in a field. Window has close relationship to door and browser. It can refer to the window on the wall and the window page in the browswer.\n",
        "3. Some polysemous words dont't work beacause the Word2Vec 10K dataset my not include the mutliple meanings of those polysemous words. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaHeader": true,
        "id": "bZNVRZotKpbC"
      },
      "source": [
        "### Problem 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaId": "77afa3bd-9ae7-444f-a52a-7c4647fa333f",
        "trusted": true,
        "editable": false,
        "deletable": false,
        "id": "pzpqfmFfKpbC"
      },
      "source": [
        "Embedding vectors have been shown to sometimes exhibit the ability to solve analogies.\n",
        "\n",
        "For example, to solve the analogy, \"man is to king as woman is to what?\".\n",
        "\n",
        "The \"man is to king\" relationship can be represented geometrically by the displacement vector between word man and king word embeddings.\n",
        "\n",
        "$\\displaystyle  v_{\\text{man}} + (v_{\\text{king}} − v_{\\text{man}}) = v_{\\text{king}}$\n",
        " \n",
        "\n",
        "The analogous relationship can then often be found by adding this displacement to the woman word embedding\n",
        " $\\displaystyle v_{\\text{woman}} + (v_{\\text{king}} − v_{\\text{man}}) \\approx v_{queen}$\n",
        " ​ \n",
        "\n",
        "The relationship is only approximate in that $v_{\\text{queen}}$ ​will be found nearby the point \n",
        "$$v_{\\text{woman}} + (v_{\\text{king}} − v_{\\text{man}})$ $\n",
        "\n",
        "### ®[5] Task: Word2Vec Analogies\n",
        "Using an online tool (e.g.,  [http://bionlp-www.utu.fi/wv_demo/ ](http://bionlp-www.utu.fi/wv_demo/ ) or [https://lamyiowce.github.io/word2viz/](https://lamyiowce.github.io/word2viz/) ) or your own colab notebook and find three different word-embedding analogies that work. \n",
        "\n",
        "Write up your findings below.  \n",
        "1. Please state each full analogy in the following form **man:king :: woman:queen **(in english this reads as \"man is to king AS woman is to queen\").\n",
        "2. Provide plots, diagrams and or calculations that support your assertion. \n",
        "3. If the analogy is complicated, explain why the analogy holds in one or two sentences.\n",
        "\n",
        "\n",
        "You may have to try several analogies to find one that works!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8fcNzlDyM_V"
      },
      "source": [
        "1.  *man:male :: woman:female *; *one:January :: two:February *; *male:father :: female:mother *\n",
        "2. The similairty for the first group is 0.749 and 0.774 and female appears within the top 10 words of woman. The similarity for second group is 0.401 and 0.467. The similarity for third group is 0.771 and 0.738. And the following graphs show that the relationship between these pairs match those existing pairs defined by the default od analogies in its category.\n",
        "3. It holds because they have the same direction and similarity, so the distance vector between two pairs are close to each other. Also, sometimes the too complicated analogy give both orthogonal vector pairs (unrelated), so that it can match another unrelated pairs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV1NAB80P6-4"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1ei9IV-2jHV3P1vG-8hfRD4Cp79CMghrG)\n",
        "![picture](https://drive.google.com/uc?id=1PChhPfEDKl_XC0YQ-IUDBG2eSM_1aabp)\n",
        "![picture](https://drive.google.com/uc?id=1ONF9YxFmfBZZ0UM50jzV_yhwESy9Un11)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaHeader": true,
        "id": "reX-UARiKpbC"
      },
      "source": [
        "### Problem 11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaId": "fc5095a0-1a81-4d43-a499-92f7c25f1400",
        "trusted": true,
        "editable": false,
        "deletable": false,
        "id": "OqLR6ElSKpbD"
      },
      "source": [
        "Original Text: [The Geometry of Culture: Analyzing the Meanings of Class through Word Embeddings](https://doi.org/10.1177%2F0003122419877135)\n",
        "\n",
        "More Direct Text: [The Geometry of Culture: Analyzing Meaning through Word Embeddings](https://paperswithcode.com/paper/the-geometry-of-culture-analyzing-meaning)\n",
        "###  \n",
        "**Instructor note: **If you have not already answered this question using the Original Text, please use the More Direct Text.  Indicate which paper you have used.\n",
        "\n",
        "### ®[5] Task: Cultural Artifacts\n",
        "Identify several biases that this papers explores.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgOxX6RHT7zl"
      },
      "source": [
        "The example gived in paper: “doctor” is consistently found to be more “white” than “black,” and “scientist” more “masculine” than “feminine.” They are gendered and racial biases. The paper also mentioned bias between social classes such as rich and poor, including jobs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaHeader": true,
        "id": "60YQK1XoKpbD"
      },
      "source": [
        "### Problem 12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaId": "02fa8e41-3d36-40fe-8a96-6824db279054",
        "trusted": true,
        "editable": false,
        "deletable": false,
        "id": "FiKn3VTDKpbD"
      },
      "source": [
        "Original Text: [The Geometry of Culture: Analyzing the Meanings of Class through Word Embeddings](https://doi.org/10.1177%2F0003122419877135)\n",
        "\n",
        "More Direct Text: [The Geometry of Culture: Analyzing Meaning through Word Embeddings](https://paperswithcode.com/paper/the-geometry-of-culture-analyzing-meaning)\n",
        "\n",
        "** Instructor note: **If you have not already answered this question using the Original Text, please use the More Direct Text.  Indicate which paper you have used.\n",
        "\n",
        "### ®[2] Task: OK, Boomer\n",
        "Describe how one of these biases change over time.  Does it agree with your impressions of how the culture in the US has been changing over time?  If you are familiar with another country's culture, what result would you expect to see?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwm9_85dVAY0"
      },
      "source": [
        "The nurse is getting away from female through years and engineer is getting away from male through years, both a little bit. It happens in my country since more girls have change to go to college and study well in physical science classes and lots of colleges start to admit boys for nursing major."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaHeader": true,
        "id": "CMFvFHJcKpbD"
      },
      "source": [
        "### Problem 13"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaId": "c00573c6-080b-458e-8fb8-30d2b14aa86f",
        "trusted": true,
        "editable": false,
        "deletable": false,
        "id": "MQSyKESLKpbD"
      },
      "source": [
        "### ®[3] Task: Unsupervised $=$ Un-biased?\n",
        "An interviewer from the ChatBots-R-Us company asks you the following question during an interview, \"We know our models learn unintentional biases because we present them with a lot of customer features, in addition to customer dialog. We think using unsupervised learning techniques will help improve the situation. What do you think?\"\n",
        "\n",
        "Please write-up your response in the cell below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LibKCZIVV4Nl"
      },
      "source": [
        "It will still be biased. Even though we don't manually set the labels, the input to the chat robots is from customers, which will include bias. Since the input is biased, we cannot prevent the chat robot from learning unintentional biases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaHeader": true,
        "id": "lxu5pmHqKpbD"
      },
      "source": [
        "### Problem 14"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaId": "d1292489-a4ad-4442-a168-04be021de2d7",
        "trusted": true,
        "editable": false,
        "deletable": false,
        "id": "w8rkOr9AKpbE"
      },
      "source": [
        "### ®[2] Task: Axis Understanding\n",
        "Use the Embedding Projector \"Custom Option\" or another tool to create an illustration similar to one found in the paper.  Document that you have done this, and explain the setup.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrNrIbjQYsxS"
      },
      "source": [
        "I choose custom and choose masculine for left, femnine for right, poor for up and rich for down. Here is the graph I generate projected to a 2D space.\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1pV9w4lSYSaA3Up88hoMxQur82ckayDA6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaHeader": true,
        "id": "hOi-EG8RKpbE"
      },
      "source": [
        "### Problem 15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaId": "31f1a333-2f48-45c6-86a0-848a6c9de2cd",
        "trusted": true,
        "editable": false,
        "deletable": false,
        "id": "xoOS3B7lKpbE"
      },
      "source": [
        "### ®[3] Task: Embeddings Variation\n",
        "Alice and Bob have used different Word2Vec algorithm implementations to obtain word embeddings on the same corpus and vocabulary of words $V$.  \n",
        "\n",
        "In particular, for every word $w$, Alice has obtained ‘context’ vectors $u^A_w$ and ‘center’ vectors $v^A_w$, and Bob has obtained ‘context’ vectors $u^B_w$ and ‘center’ vectors $v^B_w$ for every word. \n",
        "\n",
        "Suppose that, for every pair of words $w , w'\\in V$, the inner product is the same in both Alice and Bob’s model: \n",
        "\n",
        "$(u^A_w)^Tv^A_{w'}= (u ^B_w)^T v^B_{w'}$\n",
        "\n",
        "Does it follow that, for every word $w \\in V, v^A_w = v^B_w$ ?  Why or why not?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNA2QrXkb__B"
      },
      "source": [
        "No. Since the center vectors might be different from algorithm A to algorithm B. Even the distance, similairty and other features are same, the pivot and center of the projection might be different."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "prismiaHeader": true,
        "id": "8JKS8_8iKpbE"
      },
      "source": [
        "### Problem 16"
      ]
    }
  ]
}