{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0,"cells":[{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 1"]},{"cell_type":"markdown","metadata":{"prismiaId":"678d0304-349f-49c3-8285-b351da2ac208","trusted":true,"editable":false,"deletable":false},"source":["## Identifying dog images\nThe goal of this assignment is to develop models which will identify the breeds of dogs. For the dataset, you are provided with a set of images of dogs. Each image has a filename that is its unique id. The dataset comprises 120 breeds of dogs. One goal of this assignment is to create a multiclass classifier capable of determining a dog's breed from a photo.\n\nSince we do not have the labels for the test set, we will only use the files `training.zip` and `label.csv` for training and validation.\n\nAlso, the **entire assignment should be run on Colab**. Even our means of obtaining the data is going to be specific to the Google ecosystem.\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"618cb83a-8a29-42d8-a047-e29e7bf9234a","trusted":true,"editable":false,"deletable":false},"source":["### Loading Libraries\nWe begin by loading the functions we'll need throughout the assignment:\n```python\nimport keras\nfrom keras.layers import Dense, Dropout, Input, MaxPooling2D, ZeroPadding2D, Conv2D, Flatten\nfrom keras.models import Sequential, Model\nfrom keras.losses import categorical_crossentropy\nfrom keras.optimizers import Adam, SGD\nfrom keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator\nfrom keras.utils import to_categorical\nfrom tensorflow.keras import regularizers\n\nfrom tensorflow.keras.layers import MaxPool2D, AveragePooling2D, GlobalAveragePooling2D\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\n\nfrom zipfile import ZipFile\nimport time\nfrom datetime import timedelta\nfrom io import BytesIO\n\n# Image manipulation.\nimport PIL.Image\n\nimport pickle\nimport os\n\nimport random\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"618cb83a-8a29-42d8-a047-e29e7bf9234a","trusted":true,"editable":false,"deletable":false},"source":["import keras\nfrom keras.layers import Dense, Dropout, Input, MaxPooling2D, ZeroPadding2D, Conv2D, Flatten\nfrom keras.models import Sequential, Model\nfrom keras.losses import categorical_crossentropy\nfrom keras.optimizers import Adam, SGD\nfrom keras.preprocessing.image import img_to_array, load_img, ImageDataGenerator\nfrom keras.utils import to_categorical\nfrom tensorflow.keras import regularizers\n\nfrom tensorflow.keras.layers import MaxPool2D, AveragePooling2D, GlobalAveragePooling2D\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\n\nfrom zipfile import ZipFile\nimport time\nfrom datetime import timedelta\nfrom io import BytesIO\n\n# Image manipulation.\nimport PIL.Image\n\nimport pickle\nimport os\n\nimport random"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"12641660-7b98-4c1c-b163-379fb989d1b4","trusted":true,"editable":false,"deletable":false},"source":["® [5 points] What's the difference between `AveragePooling2D` and `GlobalAveragePooling2D`? The code snippet below might be helpful, as might the TensorFlow documentation.\n```python\nimport tensorflow as tf\ninput_shape = (20, 40, 50, 10)\nx = tf.random.normal(input_shape)\nprint(tf.keras.layers.GlobalAveragePooling2D()(x).shape)\nprint(tf.keras.layers.AveragePooling2D()(x).shape)\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"12641660-7b98-4c1c-b163-379fb989d1b4","trusted":true,"editable":false,"deletable":false},"source":["import tensorflow as tf\ninput_shape = (20, 40, 50, 10)\nx = tf.random.normal(input_shape)\nprint(tf.keras.layers.GlobalAveragePooling2D()(x).shape)\nprint(tf.keras.layers.AveragePooling2D()(x).shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 2"]},{"cell_type":"markdown","metadata":{"prismiaId":"a9b95c7b-c9ca-434a-a53e-95dc5e3b4a8e","trusted":true,"editable":false,"deletable":false},"source":["### Mounting the Google Drive\nBefore training a model, we must first get the data on the machine running our Colab session. To do this, we will _mount_ the Google Drive associated with your Brown account. This just means making your drive available as a directory on the Colab machine, particularly at the location `/content/drive`. If you want, you can inspect the file system of the Colab machine using the folder icon on the toolbar on the left edge of the window.\n\nThis will require a couple manual steps: \n\n1. Visit [this URL](https://drive.google.com/drive/folders/1wWF4txn6hRfE4ofG1J4ZdsCrV1HpRbEZ?usp=sharing) and add a shortcut to your \"My Drive\".\n2. Note: after this HW assignment, you can delete these shortcut to keep your GDrive tidy. If you want to put it somewhere else in your GDrive now, you will need to change the variable `path` accordingly.\n3. Run the code cell below to mount the drive. You'll have to authenticate in a separate window and copy an authentication code back to this page.\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"2eee215b-3b77-4d70-8680-090d5c2924da","trusted":true,"editable":false,"deletable":false},"source":["```python\nfrom google.colab import drive\ndrive.mount('/content/drive')\npath = \"/content/drive/MyDrive/Data/\"\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"2eee215b-3b77-4d70-8680-090d5c2924da","trusted":true,"editable":false,"deletable":false},"source":["from google.colab import drive\ndrive.mount('/content/drive')\npath = \"/content/drive/MyDrive/Data/\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"83c0d062-8eb2-43f1-af18-f0d7c7b7c526","trusted":true,"editable":false,"deletable":false},"source":["### Unzip the zip file for the training data\nThe training data comes in the form of a zip file containing many image files. We can access these file names using the `namelist` method of the `ZipFile` object produced below.\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"12d50962-9c60-4f08-8b62-2d8fe0ed0e14","trusted":true,"editable":false,"deletable":false},"source":["```python\narchive_train = ZipFile(path + \"train.zip\", 'r')\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"12d50962-9c60-4f08-8b62-2d8fe0ed0e14","trusted":true,"editable":false,"deletable":false},"source":["archive_train = ZipFile(path + \"train.zip\", 'r')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"0f36a1d6-0fdd-4ef3-837c-dcbb5b65716c","trusted":true,"editable":false,"deletable":false},"source":["® How many files do we have in the training set? Note that the object returned by the `namelist` method is a generator, so you will have to convert it to a `list` to find its length.\n"]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 3"]},{"cell_type":"markdown","metadata":{"prismiaId":"57766342-a793-42b0-aaef-1476524e3059","trusted":true,"editable":false,"deletable":false},"source":["### Reading the Labels\nThe label.csv should contain two columns: `id` and `breed`.\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"2929b74a-033d-4f0b-858f-3e718a2e9f28","trusted":true,"editable":false,"deletable":false},"source":["```python\nlabels_raw = pd.read_csv(path + \"labels.csv\", \n                         header=0, sep=',', quotechar='\"')\n# Look at the first five rows:\nlabels_raw.head(5)\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"2929b74a-033d-4f0b-858f-3e718a2e9f28","trusted":true,"editable":false,"deletable":false},"source":["labels_raw = pd.read_csv(path + \"labels.csv\", \n                         header=0, sep=',', quotechar='\"')\n# Look at the first five rows:\nlabels_raw.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"50823d7d-3b9e-4631-9e53-98b629f4ed5d","trusted":true,"editable":false,"deletable":false},"source":["® How many images do we have for each breed in this dataset? Hint: investigate the Pandas method `value_counts`.\n"]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 4"]},{"cell_type":"markdown","metadata":{"prismiaId":"992e9315-0bd8-4f83-9016-6b07655bc511","trusted":true,"editable":false,"deletable":false},"source":["Let's make a visualization for the collection of counts for each breed:\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"532df94a-fdf6-40dd-aa1a-f2123676974b","trusted":true,"editable":false,"deletable":false},"source":["```python\nax = (labels_raw.value_counts(labels_raw['breed'], ascending=True)\n                 .plot(kind='barh', fontsize=\"20\", \n                       title=\"Class Distribution\", figsize=(15,40)))\n\nax.set(xlabel=\"Images per class\", ylabel=\"Classes\")\nax.xaxis.label.set_size(20)\nax.yaxis.label.set_size(20)\nax.title.set_size(30)\nplt.show()\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"532df94a-fdf6-40dd-aa1a-f2123676974b","trusted":true,"editable":false,"deletable":false},"source":["ax = (labels_raw.value_counts(labels_raw['breed'], ascending=True)\n                 .plot(kind='barh', fontsize=\"20\", \n                       title=\"Class Distribution\", figsize=(15,40)))\n\nax.set(xlabel=\"Images per class\", ylabel=\"Classes\")\nax.xaxis.label.set_size(20)\nax.yaxis.label.set_size(20)\nax.title.set_size(30)\nplt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"8b6ad614-451d-4e91-a8c1-96c5b66df71e","trusted":true,"editable":false,"deletable":false},"source":["### Extracting and Organizing\nNext, we will create a NumPy `ndarray` for all of the images and store the array using Python's `pickle` module. We will compress the images to a smaller dimension due to limited computational resources. It takes 1-2 minutes to create this pickle file due to the large number of images. The pickle file is saved in the temporary folder and will be deleted if you lose connection to the kernel. You can also modify the saving folder yourself to save it somewhere in your GDrive so you can directly read the file later.\n\n_Note: making pickle files is like writing Python data structures directly to disk from your Python session. They're high-fidelity and efficient for Python, but they're not really useful for anything other than loading back into a Python session._\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"c023f2dc-6433-4633-99d4-01305134b10a","trusted":true,"editable":false,"deletable":false},"source":["```python\n# images will be re-sized to 96 by 96:\nimage_resize = 96\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"c023f2dc-6433-4633-99d4-01305134b10a","trusted":true,"editable":false,"deletable":false},"source":["# images will be re-sized to 96 by 96:\nimage_resize = 96"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"29372de0-1a30-47e3-95b3-998a4b4bf0dc","trusted":true,"editable":false,"deletable":false},"source":["```python\ndef pickle_creator(archivezip, nwidth, nheight, save_name):\n    # We choose the archive (zip file) + the new nwidth and height for all the image which will be reshaped\n    \n    # Start-time used for printing time-usage below.\n    start_time = time.time()\n    \n    s = (len(archivezip.namelist()[:])-1, nwidth, nheight,3) # nwidth x nheight = number of features because images are nwigth x nheight pixels\n    allImage = np.zeros(s)\n    labels = np.empty(len(archivezip.namelist()[:])-1, dtype = \"object\")\n    for i in range(1,len(archivezip.namelist()[:])):\n        filename = BytesIO(archivezip.read(archivezip.namelist()[i]))\n        image = PIL.Image.open(filename) # open colour image\n        image = image.resize((nwidth, nheight))\n        image = np.array(image)\n        image = np.clip(image/255.0, 0.0, 1.0) #255 = max of the value of a pixel\n\n        allImage[i-1]=image\n        labels[i-1]=list(labels_raw[labels_raw['id']==archivezip.namelist()[i][:-4]]['breed'])[0]\n    # we save the newly created data\n    pickle.dump(allImage, open( save_name + '.pickle', \"wb\" ,) ,protocol=4)\n    pickle.dump(labels, open( save_name + 'labels' + '.pickle', \"wb\" ),protocol=4 )\n    # Ending time.\n    end_time = time.time()\n\n    # Difference between start and end-times.\n    time_dif = end_time - start_time\n\n    # Print how much time it took:\n    print(\"Time elapsed: \" + str(timedelta(seconds=int(round(time_dif)))))\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"29372de0-1a30-47e3-95b3-998a4b4bf0dc","trusted":true,"editable":false,"deletable":false},"source":["def pickle_creator(archivezip, nwidth, nheight, save_name):\n    # We choose the archive (zip file) + the new nwidth and height for all the image which will be reshaped\n    \n    # Start-time used for printing time-usage below.\n    start_time = time.time()\n    \n    s = (len(archivezip.namelist()[:])-1, nwidth, nheight,3) # nwidth x nheight = number of features because images are nwigth x nheight pixels\n    allImage = np.zeros(s)\n    labels = np.empty(len(archivezip.namelist()[:])-1, dtype = \"object\")\n    for i in range(1,len(archivezip.namelist()[:])):\n        filename = BytesIO(archivezip.read(archivezip.namelist()[i]))\n        image = PIL.Image.open(filename) # open colour image\n        image = image.resize((nwidth, nheight))\n        image = np.array(image)\n        image = np.clip(image/255.0, 0.0, 1.0) #255 = max of the value of a pixel\n\n        allImage[i-1]=image\n        labels[i-1]=list(labels_raw[labels_raw['id']==archivezip.namelist()[i][:-4]]['breed'])[0]\n    # we save the newly created data\n    pickle.dump(allImage, open( save_name + '.pickle', \"wb\" ,) ,protocol=4)\n    pickle.dump(labels, open( save_name + 'labels' + '.pickle', \"wb\" ),protocol=4 )\n    # Ending time.\n    end_time = time.time()\n\n    # Difference between start and end-times.\n    time_dif = end_time - start_time\n\n    # Print how much time it took:\n    print(\"Time elapsed: \" + str(timedelta(seconds=int(round(time_dif)))))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"3460bc54-906f-4b5a-90c0-16a5359b0c54","trusted":true,"editable":false,"deletable":false},"source":["```python\npickle_creator(archivezip = archive_train, nwidth = image_resize, nheight = image_resize , save_name = \"/content/drive/MyDrive/train\")\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"3460bc54-906f-4b5a-90c0-16a5359b0c54","trusted":true,"editable":false,"deletable":false},"source":["pickle_creator(archivezip = archive_train, nwidth = image_resize, nheight = image_resize , save_name = \"/content/drive/MyDrive/train\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"bd4120ca-39c4-42a8-b0cd-9e0886b5a47a","trusted":true,"editable":false,"deletable":false},"source":["® Show a couple of the original images side-by-side with their re-sized versions. What algorithm is Pillow using to downsample the images?\n"]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 5"]},{"cell_type":"markdown","metadata":{"prismiaId":"8e98b996-9693-4265-b558-dae0ae35a7cc","trusted":true,"editable":false,"deletable":false},"source":["Now let's load our training data:\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"2fb81a56-35ec-4d14-8824-c360951ff779","trusted":true,"editable":false,"deletable":false},"source":["```python\ntrain = pickle.load( open( \"/content/drive/MyDrive/train.pickle\", \"rb\" ) )\nlabels = pickle.load( open( \"/content/drive/MyDrive/trainlabels.pickle\", \"rb\" ) )\nprint(train.shape)\nprint(labels.shape)\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"2fb81a56-35ec-4d14-8824-c360951ff779","trusted":true,"editable":false,"deletable":false},"source":["train = pickle.load( open( \"/content/drive/MyDrive/train.pickle\", \"rb\" ) )\nlabels = pickle.load( open( \"/content/drive/MyDrive/trainlabels.pickle\", \"rb\" ) )\nprint(train.shape)\nprint(labels.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"1c436902-30df-4fa3-a4d1-e657e496fa4b","trusted":true,"editable":false,"deletable":false},"source":["### Select the top 16 breeds for this homework\n® Write code to select the 16 most-represented dog breeds in the dataset for this homework. So this will be a 16-class classification problem.\n\nApart from this homework, you are welcome to see how it changes things to increase or decrease the number of breeds. However, for now let's stick to 16.\n\nTo help make sure you're on the right track, the result of your code for this problem should be to define a variable called `labels_filtered` which contains 1777 labels and another variable called `train_filtered` which contains a 1777 by 96 by 96 by 3 array. You can sanity check further using this snippet, which will show some of the images alongside the corresponding label:\n```python\nfor i in range(5):\n  random_index = random.randint(1,len(labels_filtered))\n  print(labels_filtered[random_index])\n  lum_img = train_filtered[random_index,:,:,:]\n  plt.imshow(lum_img)\n  plt.show()\n```\nAlso, be sure to define `n_breeds = 16`, as we'll use that variable later.\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"1c436902-30df-4fa3-a4d1-e657e496fa4b","trusted":true,"editable":false,"deletable":false},"source":["for i in range(5):\n  random_index = random.randint(1,len(labels_filtered))\n  print(labels_filtered[random_index])\n  lum_img = train_filtered[random_index,:,:,:]\n  plt.imshow(lum_img)\n  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 6"]},{"cell_type":"markdown","metadata":{"prismiaId":"3e256fbb-4974-44b4-98d5-f39bbb4fc9eb","trusted":true,"editable":false,"deletable":false},"source":["### Train-test Split and Data Generator\nWe will take 80% of the data as training and 20% as validation. We will use `ImageDataGenerator` to fit the data in the model. Keras `ImageDataGenerator` class provides a quick and easy way to augment your images. It provides a host of different augmentation techniques like standardization, rotation, shifts, flips, brightness change, and many more. You can find more on its official [documentation page](https://keras.io/api/preprocessing/image/).\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"54ebc863-980a-4a43-8a48-107d41588beb","trusted":true,"editable":false,"deletable":false},"source":["We'll begin by reshaping the `labels` array and representing it as a dense, 16-column array:\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"72089160-2291-4a95-b1f1-1c33bb2cbce1","trusted":true,"editable":false,"deletable":false},"source":["```python\nlabels = labels_filtered\nlabels = labels.reshape(labels.shape[0],1)\nlabels = pd.get_dummies(labels_filtered)\nlabels.shape\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"72089160-2291-4a95-b1f1-1c33bb2cbce1","trusted":true,"editable":false,"deletable":false},"source":["labels = labels_filtered\nlabels = labels.reshape(labels.shape[0],1)\nlabels = pd.get_dummies(labels_filtered)\nlabels.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"b2585b68-1221-4890-8c57-2d0851cb4651","trusted":true,"editable":false,"deletable":false},"source":["Next, let's double-check all of the dimensions of the tensors involved:\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"e6a2b76b-a3ce-4a84-beb1-fc52c6abaa18","trusted":true,"editable":false,"deletable":false},"source":["```python\nrandom.seed(2040)\nX = train_filtered\ny = labels\nprint(X.shape)\nprint(y.shape)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"e6a2b76b-a3ce-4a84-beb1-fc52c6abaa18","trusted":true,"editable":false,"deletable":false},"source":["random.seed(2040)\nX = train_filtered\ny = labels\nprint(X.shape)\nprint(y.shape)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"f59c972e-b7bb-4fe2-8f1b-f13bb3dbfa71","trusted":true,"editable":false,"deletable":false},"source":["And now we'll create the data generator:\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"8cd32df0-ff62-47e7-97b7-9a647931eb41","trusted":true,"editable":false,"deletable":false},"source":["```python\ntrain_datagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.3,\n    height_shift_range=0.3,\n    shear_range=0.3,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\ntest_datagen = ImageDataGenerator()\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"8cd32df0-ff62-47e7-97b7-9a647931eb41","trusted":true,"editable":false,"deletable":false},"source":["train_datagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.3,\n    height_shift_range=0.3,\n    shear_range=0.3,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\ntest_datagen = ImageDataGenerator()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"66805f37-846d-4158-960f-9bfcc5621d08","trusted":true,"editable":false,"deletable":false},"source":["® What's the difference between a generator and an iterable (in Python parlance)? Which is `ImageDataGenerator` (hint: might be a trick question!)? \n\nWhy is this distinction particularly relevant in this context?\n"]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 7"]},{"cell_type":"markdown","metadata":{"prismiaId":"2fd4cb68-0420-4a12-b746-d3844f68d5d8","trusted":true,"editable":false,"deletable":false},"source":["### Models and Training\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"892b197f-bd63-42cf-8313-d7c165adae5d","trusted":true,"editable":false,"deletable":false},"source":["To train this model, we'll begin by batching the data output by the image generator:\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"dcd79725-a2df-4b94-946a-11210698903e","trusted":true,"editable":false,"deletable":false},"source":["```python\nBATCH_SIZE = 10 # You can modify this\ntraining_set = train_datagen.flow(X_train, y=y_train, batch_size=BATCH_SIZE)\ntesting_set = test_datagen.flow(X_test, y=y_test, batch_size=BATCH_SIZE)\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"dcd79725-a2df-4b94-946a-11210698903e","trusted":true,"editable":false,"deletable":false},"source":["BATCH_SIZE = 10 # You can modify this\ntraining_set = train_datagen.flow(X_train, y=y_train, batch_size=BATCH_SIZE)\ntesting_set = test_datagen.flow(X_test, y=y_test, batch_size=BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"a1904b2f-19b2-49cc-b5a2-19d9aee3a3a1","trusted":true,"editable":false,"deletable":false},"source":["#### Model 1: Basic CNN Model\nIn this task, the basic CNN archtecture should be as followed :\n- Convolutional Layer with 32 filters which are each $3 \\times 3$a.\n\n\n- Max pooling\n- Relu\n\n\n- Convolutional Layer with 3 by 3 filters (64 of them)\n\n\n- Max pooling\n- Relu\n\n\n- Convolutional Layer with 3*3 filters (128 of them)\n\n\n- Max pooling\n- Relu\n- DropOut Rate 0.2\n\n\n- Flatten Layer\n- Fully Connected Layer with 500 nodes\n\n\n- Relu\n- DropOut Rate 0.2\n\n\n- Fully Connected Layer with n nodes (n = number of breeds) and softmax activation\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"17d6f815-e06c-4f2c-8dc1-dd906b5fc277","trusted":true,"editable":false,"deletable":false},"source":["```python\ndef build_model():\n  inputs = Input(shape = (image_resize, image_resize, 3))\n  model = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), input_shape=(image_resize, image_resize, 3))(inputs)\n\n  model = MaxPool2D(pool_size=(2, 2))(model)\n  model = Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(l=0.01))(model)\n  model = MaxPool2D(pool_size=(2, 2))(model)\n  model = Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(l=0.01))(model)\n  model = MaxPool2D(pool_size=(2, 2))(model)\n  model = Dropout(rate=0.2)(model)\n  # model = Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(l=0.01))(model)\n  # model = MaxPool2D(pool_size=(2, 2))(model)\n  # model = Dropout(rate=0.2)(model)\n  model = Flatten()(model)\n  model = Dense(500, activation = \"relu\", kernel_initializer=\"he_normal\")(model)\n  model = Dropout(rate=0.2)(model)\n  # model = Dense(100, activation = \"relu\", kernel_initializer=\"he_normal\")(model)\n  out = Dense(n_breeds, activation = 'softmax')(model)\n  model = Model(inputs=inputs, outputs=out)\n  return model\n\nmodel = build_model()\n\nopt = keras.optimizers.Adam(learning_rate=0.00005)\nmodel.compile(loss=categorical_crossentropy,optimizer=opt,metrics=['accuracy'])\nmodel.summary()\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"17d6f815-e06c-4f2c-8dc1-dd906b5fc277","trusted":true,"editable":false,"deletable":false},"source":["def build_model():\n  inputs = Input(shape = (image_resize, image_resize, 3))\n  model = Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(l=0.01), input_shape=(image_resize, image_resize, 3))(inputs)\n\n  model = MaxPool2D(pool_size=(2, 2))(model)\n  model = Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(l=0.01))(model)\n  model = MaxPool2D(pool_size=(2, 2))(model)\n  model = Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(l=0.01))(model)\n  model = MaxPool2D(pool_size=(2, 2))(model)\n  model = Dropout(rate=0.2)(model)\n  # model = Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(l=0.01))(model)\n  # model = MaxPool2D(pool_size=(2, 2))(model)\n  # model = Dropout(rate=0.2)(model)\n  model = Flatten()(model)\n  model = Dense(500, activation = \"relu\", kernel_initializer=\"he_normal\")(model)\n  model = Dropout(rate=0.2)(model)\n  # model = Dense(100, activation = \"relu\", kernel_initializer=\"he_normal\")(model)\n  out = Dense(n_breeds, activation = 'softmax')(model)\n  model = Model(inputs=inputs, outputs=out)\n  return model\n\nmodel = build_model()\n\nopt = keras.optimizers.Adam(learning_rate=0.00005)\nmodel.compile(loss=categorical_crossentropy,optimizer=opt,metrics=['accuracy'])\nmodel.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"d985c37c-8082-461e-bcaf-b4bf2c105228","trusted":true,"editable":false,"deletable":false},"source":["Now we'll train the model:\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"f05f73f0-a96d-4f9d-b987-4e396d93e7ce","trusted":true,"editable":false,"deletable":false},"source":["```python\nhistory = model.fit(\n  training_set, \n  steps_per_epoch = X_train.shape[0] // BATCH_SIZE,\n  validation_data = testing_set, \n  epochs = 100, \n  verbose = 1\n)\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"f05f73f0-a96d-4f9d-b987-4e396d93e7ce","trusted":true,"editable":false,"deletable":false},"source":["history = model.fit(\n  training_set, \n  steps_per_epoch = X_train.shape[0] // BATCH_SIZE,\n  validation_data = testing_set, \n  epochs = 100, \n  verbose = 1\n)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"0bddfcff-f1ea-4311-b485-c0a201937abb","trusted":true,"editable":false,"deletable":false},"source":["#### Model 2\n® Slightly modify the CNN structure we built above. Feel free to add up to two convolutional layers and adjust the dropout rate, change the activation function and add regularization. \n\n```python\ndef build_model_own():\n\n  #### TASK: Build your own model here ####\n\n  return model\n\nmy_model = build_model_own()\n\nopt = keras.optimizers.Adam(learning_rate=0.00005)\n\nmy_model.compile(loss=categorical_crossentropy,optimizer=opt,metrics=['accuracy'])\n\nprint(my_model.summary())\n\nhistory_mymodel = my_model.fit(\n  training_set, \n  steps_per_epoch = X_train.shape[0] // BATCH_SIZE,\n  validation_data = testing_set, \n  epochs = 100, \n  verbose = 1\n)\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"0bddfcff-f1ea-4311-b485-c0a201937abb","trusted":true,"editable":false,"deletable":false},"source":["def build_model_own():\n\n  #### TASK: Build your own model here ####\n\n  return model\n\nmy_model = build_model_own()\n\nopt = keras.optimizers.Adam(learning_rate=0.00005)\n\nmy_model.compile(loss=categorical_crossentropy,optimizer=opt,metrics=['accuracy'])\n\nprint(my_model.summary())\n\nhistory_mymodel = my_model.fit(\n  training_set, \n  steps_per_epoch = X_train.shape[0] // BATCH_SIZE,\n  validation_data = testing_set, \n  epochs = 100, \n  verbose = 1\n)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 8"]},{"cell_type":"markdown","metadata":{"prismiaId":"539219a4-60c9-4576-b648-7ca969bdd273","trusted":true,"editable":false,"deletable":false},"source":["### Transfer Learning using VGG16\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"7d60c493-62f3-4587-b354-3c2cebe2feb1","trusted":true,"editable":false,"deletable":false},"source":["Transfer learning consists of taking features learned on one problem, and leveraging them on a new, similar problem. For instance, features from a model that has learned to identify racoons may be useful to kick-start a model meant to identify [tanukis](https://en.wikipedia.org/wiki/Japanese_raccoon_dog). For the following model, we will use VGG16 we learnt in class to be our base model structure, followed by dense layers.\n\n#### Model 3\nThe model structure should be:\n- VGG16 with `imagenet` retrained weights\n- Fully Connected Layer with 512 nodes\n\n\n- Relu\n- DropOut Rate 0.25\n\n\n- Fully Connected Layer with 256 nodes\n\n\n- Relu\n- DropOut Rate 0.25\n\n\n- Fully Connected Layer with 128 nodes\n\n\n- Relu\n- DropOut Rate 0.25 \n\n\n- Fully Connected Layer with n nodes (n = number of breeds) and softmax\n\n\nHere's some code to get you started:\n```python\nfrom keras.applications.vgg16 import VGG16\ndef build_vgg():\n  inputshape = X_train[0].shape\n  base_model = VGG16(weights = 'imagenet', include_top = False, input_shape=inputshape)\n  x = base_model.output\n  ### DO EXTRA LAYERS HERE\n  model = Model(inputs = base_model.input, outputs = predictions)\n  return model\nmodel_vgg = build_vgg()\nmodel_vgg.compile(Adam(lr=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\nhistory_vgg = model_vgg.fit(training_set,\n                            steps_per_epoch = X_train.shape[0] // BATCH_SIZE,\n                            validation_data = testing_set, epochs = 300, verbose = 1)\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"7d60c493-62f3-4587-b354-3c2cebe2feb1","trusted":true,"editable":false,"deletable":false},"source":["from keras.applications.vgg16 import VGG16\ndef build_vgg():\n  inputshape = X_train[0].shape\n  base_model = VGG16(weights = 'imagenet', include_top = False, input_shape=inputshape)\n  x = base_model.output\n  ### DO EXTRA LAYERS HERE\n  model = Model(inputs = base_model.input, outputs = predictions)\n  return model\nmodel_vgg = build_vgg()\nmodel_vgg.compile(Adam(lr=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\nhistory_vgg = model_vgg.fit(training_set,\n                            steps_per_epoch = X_train.shape[0] // BATCH_SIZE,\n                            validation_data = testing_set, epochs = 300, verbose = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"31e32d89-f15a-4ec9-81a6-6d30681315b3","trusted":true,"editable":false,"deletable":false},"source":["### Check Some of the Predictions\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"793ab1d4-a307-4710-b83b-ddd45b9fd0f7","trusted":true,"editable":false,"deletable":false},"source":["We can check our work in the previous problem by displaying some example images of dogs alongside their actual breed and the model-predicted breed:\n"]},{"cell_type":"markdown","metadata":{"prismiaId":"9bc855f5-f3cd-482f-af4b-d2f6d8f3a586","trusted":true,"editable":false,"deletable":false},"source":["```python\nj = int(np.sqrt(n_breeds))\ni = int(np.ceil(n_breeds / j))\nfig = plt.figure(1, figsize=(16, 16))\ngrid = ImageGrid(fig, 111, nrows_ncols=(i, j), axes_pad=0.05)\nclasses = list(y_train.columns)\n\nfor i, breed in enumerate(list(labels.columns.unique())):\n    ax = grid[i]\n    img_index = list(y_test[breed]==1).index(True)\n    ax.imshow(X_test[img_index])\n    x = X_test[img_index].reshape(1,image_resize,image_resize,3)\n    preds = model_vgg.predict(x)\n    prob = preds.max()\n    class_name = classes[np.argmax(preds)]\n    ax.text(10, image_resize-15, 'Model Prediction: %s (%.2f)' % (class_name, prob), color='w', backgroundcolor='k', alpha=0.8)\n    ax.text(10, image_resize-5, 'TRUE LABEL: %s' % breed, color='k', backgroundcolor='w', alpha=0.8)\n    ax.axis('off')\n\nplt.show()\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"9bc855f5-f3cd-482f-af4b-d2f6d8f3a586","trusted":true,"editable":false,"deletable":false},"source":["j = int(np.sqrt(n_breeds))\ni = int(np.ceil(n_breeds / j))\nfig = plt.figure(1, figsize=(16, 16))\ngrid = ImageGrid(fig, 111, nrows_ncols=(i, j), axes_pad=0.05)\nclasses = list(y_train.columns)\n\nfor i, breed in enumerate(list(labels.columns.unique())):\n    ax = grid[i]\n    img_index = list(y_test[breed]==1).index(True)\n    ax.imshow(X_test[img_index])\n    x = X_test[img_index].reshape(1,image_resize,image_resize,3)\n    preds = model_vgg.predict(x)\n    prob = preds.max()\n    class_name = classes[np.argmax(preds)]\n    ax.text(10, image_resize-15, 'Model Prediction: %s (%.2f)' % (class_name, prob), color='w', backgroundcolor='k', alpha=0.8)\n    ax.text(10, image_resize-5, 'TRUE LABEL: %s' % breed, color='k', backgroundcolor='w', alpha=0.8)\n    ax.axis('off')\n\nplt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaId":"80310a58-9c93-47a3-b83c-2d40c4438034","trusted":true,"editable":false,"deletable":false},"source":["® Did the transfer learning model outperform the models which were trained from scratch?\n"]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 9"]},{"cell_type":"markdown","metadata":{"prismiaId":"8f485506-5169-4020-a1a4-f3ead007f73b","trusted":true,"editable":false,"deletable":false},"source":["### Let us finally predict a TA's pet!\n® One of our TAs, Becky, has a puppy. This puppy is one of the breeds in our classification model! Load the photo of her and see whether the model can correctly predict the breed!\n```python\nbecky_pet = load_img(path+\"becky.jpg\", \n                     target_size=(image_resize, image_resize))\nbecky_pet = img_to_array(becky_pet)/255\nplt.imshow(becky_pet)\n```\n"]},{"cell_type":"code","metadata":{"prismiaParentId":"8f485506-5169-4020-a1a4-f3ead007f73b","trusted":true,"editable":false,"deletable":false},"source":["becky_pet = load_img(path+\"becky.jpg\", \n                     target_size=(image_resize, image_resize))\nbecky_pet = img_to_array(becky_pet)/255\nplt.imshow(becky_pet)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 10"]},{"cell_type":"markdown","metadata":{"prismiaId":"48026940-9e27-42a9-9db2-d433ac7d3336","trusted":true,"editable":false,"deletable":false},"source":["® Try modifying the batch size for the training of the first convnet model. What tradeoffs do you observe, particularly regarding how quickly the model trains?\n"]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 11"]},{"cell_type":"markdown","metadata":{"prismiaId":"acd0abbd-babe-4051-b02d-644129c954cb","trusted":true,"editable":false,"deletable":false},"source":["® In the transfer learning example, we trained the entire network. However, it's common to _freeze_ layers in the base model and only train the layers added on top. You can read about how to do this in Keras [here](https://keras.io/getting_started/faq/#how-can-i-freeze-layers-and-do-finetuning). How does this change affect training time and model performance?\n"]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 12"]},{"cell_type":"markdown","metadata":{"prismiaId":"a317c6f2-3b24-4b56-a090-8586dbc2cfeb","trusted":true,"editable":false,"deletable":false},"source":["® Check out [this amazing website](http://www.cs.cmu.edu/~aharley/vis/conv/) by Adam Harley. Choose some digit other than 1 and draw it in the box in the top left part of the window.![](https://firebasestorage.googleapis.com/v0/b/prismia.appspot.com/o/user-images%252FScreen%2520Shot%25202021-02-09%2520at%25209-7822d8b8-c704-4fa5-9352-b5d168c25c9e.png?alt=media&token=4d5dcd27-32fd-43a4-92ea-90864d6273cf)\n1. At which layer of the network can you no longer visually recognize the digit?\n2. Consider a single neuron in the fourth layer (the one where each box is 5 by 5). How many neurons in previous (third) layer are in that neuron's receptive field?\n3. For the same neuron as in part 2: how many neurons in the _second_ layer are in that neuron's receptive field?\n4. Try drawing the same digit repeatedly, attempting to make the digit look somewhat different each time (off-enter, or with a smaller loop or a bit of an extra curve somewhere). Are there any units in the penultimate layer which serve as a bellwether, activating strongly when your particular digit is drawn. (Note that you can check a unit's index by clicking on it.)\n"]},{"cell_type":"markdown","metadata":{"prismiaHeader":true},"source":["### Problem 13"]}]}